import pandas as pd
import numpy as np
import os
import traceback
from datetime import datetime
try:
    import geopandas as gpd
    GEOPANDAS_AVAILABLE = True
except ImportError:
    GEOPANDAS_AVAILABLE = False
    print("è­¦å‘Š: ç„¡æ³•å°å…¥ geopandasï¼Œåœ°ç†è³‡æ–™åŠŸèƒ½å°‡å—é™")

# æ•¸æ“šæ–‡ä»¶è·¯å¾‘
POPULATION_DATA_PATH = 'data/110å¹´æ¡ƒåœ’å¸‚äººå£æ•¸æŒ‰æ€§åˆ¥åŠå¹´é½¡åˆ†.xlsx'
INCOME_DATA_PATH = 'data/110_income_by_district.csv'
GEOJSON_PATH = 'data/taoyuan_districts.geojson'
COMMERCIAL_CSV_PATH = 'data/110å¹´12æœˆåº•å•†æ¥­è¡Œæ¥­åˆ¥åŠè¡Œæ”¿å€åŸŸå®¶æ•¸.csv'
PUBLIC_INFRASTRUCTURE_PATH = 'data/110æ¡ƒåœ’å¸‚å…¬å…±å»ºè¨­.xlsx'
HEALTH_DATA_PATH = 'data/110æ¡ƒåœ’å¸‚è¡›ç”Ÿ.xlsx'

# æ¡ƒåœ’å¸‚13å€‹è¡Œæ”¿å€
TAOYUAN_DISTRICTS = [
    'ä¸­å£¢', 'å…«å¾·', 'å¤§åœ’', 'å¤§æºª', 'å¹³é®', 'å¾©èˆˆ', 
    'æ¡ƒåœ’', 'æ–°å±‹', 'æ¥Šæ¢…', 'é¾æ½­', 'é¾œå±±', 'è˜†ç«¹', 'è§€éŸ³'
]

def clean_numeric_data(series):
    """
    æ¸…ç†æ•¸å€¼æ•¸æ“šçš„é€šç”¨å‡½æ•¸
    """
    return pd.to_numeric(
        series.astype(str)
        .str.replace(',', '')
        .str.replace(' ', '')
        .str.replace('-', '0')
        .str.replace('ï¼', '0'), 
        errors='coerce'
    ).fillna(0)

def load_raw_population_data():
    """è¼‰å…¥åŸå§‹äººå£è³‡æ–™ - åªé€²è¡ŒåŸºæœ¬æ¸…ç†ï¼Œä¸è¨ˆç®—ç‰¹å¾µ"""
    print("ğŸ“‚ è¼‰å…¥åŸå§‹äººå£è³‡æ–™...")
    try:
        if not os.path.exists(POPULATION_DATA_PATH):
            print(f"âŒ äººå£è³‡æ–™æª”æ¡ˆæœªæ‰¾åˆ°: {POPULATION_DATA_PATH}")
            return pd.DataFrame()
        
        # è®€å–Excelæ–‡ä»¶
        df_raw = pd.read_excel(POPULATION_DATA_PATH, header=3)
        df_raw.columns = df_raw.columns.str.strip()
        
        # ç¯©é¸æ¡ƒåœ’å¸‚13å€‹è¡Œæ”¿å€çš„ç”·å¥³æ•¸æ“š
        taoyuan_district_names = [name + 'å€' for name in TAOYUAN_DISTRICTS]
        df_taoyuan = df_raw[
            df_raw['å€åŸŸåˆ¥'].isin(taoyuan_district_names) & 
            df_raw['æ€§åˆ¥'].isin(['ç”·', 'å¥³'])
        ].copy()
        
        if df_taoyuan.empty:
            print("âŒ æœªæ‰¾åˆ°æ¡ƒåœ’å¸‚è¡Œæ”¿å€äººå£æ•¸æ“š")
            return pd.DataFrame()
        
        print(f"âœ… æˆåŠŸè¼‰å…¥ {len(df_taoyuan['å€åŸŸåˆ¥'].unique())} å€‹è¡Œæ”¿å€çš„äººå£æ•¸æ“š")
        return df_taoyuan
        
    except Exception as e:
        print(f"âŒ è¼‰å…¥äººå£è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return pd.DataFrame()

def load_raw_commercial_data():
    """è¼‰å…¥åŸå§‹å•†æ¥­è³‡æ–™ - åªé€²è¡ŒåŸºæœ¬æ¸…ç†ï¼Œä¸è¨ˆç®—æŒ‡æ¨™"""
    print("ğŸ“‚ è¼‰å…¥åŸå§‹å•†æ¥­è³‡æ–™...")
    try:
        if not os.path.exists(COMMERCIAL_CSV_PATH):
            print(f"âŒ å•†æ¥­è³‡æ–™æª”æ¡ˆæœªæ‰¾åˆ°: {COMMERCIAL_CSV_PATH}")
            return pd.DataFrame()
        
        # å˜—è©¦ä¸åŒç·¨ç¢¼è®€å–CSV
        encodings = ['utf-8', 'big5', 'cp950', 'gbk', 'latin1']
        df_commercial = None
        
        for encoding in encodings:
            try:
                df_commercial = pd.read_csv(COMMERCIAL_CSV_PATH, encoding=encoding)
                print(f"  ä½¿ç”¨ {encoding} ç·¨ç¢¼æˆåŠŸè®€å–")
                break
            except UnicodeDecodeError:
                continue
        
        if df_commercial is None:
            print("âŒ ç„¡æ³•è®€å–å•†æ¥­è³‡æ–™CSVæ–‡ä»¶")
            return pd.DataFrame()
        
        # é‡å‘½åç¬¬ä¸€å€‹æ¬„ä½
        if 'è¡Œæ”¿å€åˆ¥è¡Œæ¥­åˆ¥' in df_commercial.columns:
            df_commercial = df_commercial.rename(columns={'è¡Œæ”¿å€åˆ¥è¡Œæ¥­åˆ¥': 'å€åŸŸåˆ¥'})
        
        print(f"âœ… æˆåŠŸè¼‰å…¥å•†æ¥­è³‡æ–™ï¼Œå½¢ç‹€: {df_commercial.shape}")
        return df_commercial
        
    except Exception as e:
        print(f"âŒ è¼‰å…¥å•†æ¥­è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return pd.DataFrame()

def load_raw_income_data():
    """è¼‰å…¥åŸå§‹æ‰€å¾—è³‡æ–™ - åªé€²è¡ŒåŸºæœ¬æ¸…ç†"""
    print("ğŸ“‚ è¼‰å…¥åŸå§‹æ‰€å¾—è³‡æ–™...")
    try:
        if not os.path.exists(INCOME_DATA_PATH):
            print(f"âŒ æ‰€å¾—è³‡æ–™æª”æ¡ˆæœªæ‰¾åˆ°: {INCOME_DATA_PATH}")
            return pd.DataFrame()
        
        df_income = pd.read_csv(INCOME_DATA_PATH, encoding='utf-8')
        df_income.columns = [col.lstrip('\ufeff') for col in df_income.columns]
        
        # ç¯©é¸æ¡ƒåœ’å¸‚è³‡æ–™
        taoyuan_mask = df_income['ç¸£å¸‚åˆ¥'].str.contains('æ¡ƒåœ’å¸‚', na=False)
        df_taoyuan_income = df_income[taoyuan_mask].copy()
        
        # æå–å€åŸŸè³‡è¨Š
        df_taoyuan_income['å€åŸŸåˆ¥'] = df_taoyuan_income['ç¸£å¸‚åˆ¥'].str.extract(r'æ¡ƒåœ’å¸‚(.+?)å€')[0] + 'å€'
        df_taoyuan_income = df_taoyuan_income.dropna(subset=['å€åŸŸåˆ¥'])
        
        print(f"âœ… æˆåŠŸè¼‰å…¥æ‰€å¾—è³‡æ–™ï¼Œå½¢ç‹€: {df_taoyuan_income.shape}")
        return df_taoyuan_income
        
    except Exception as e:
        print(f"âŒ è¼‰å…¥æ‰€å¾—è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return pd.DataFrame()

def load_raw_geo_data():
    """è¼‰å…¥åŸå§‹åœ°ç†è³‡æ–™ - åªé€²è¡ŒåŸºæœ¬æ¸…ç†"""
    print("ğŸ“‚ è¼‰å…¥åŸå§‹åœ°ç†è³‡æ–™...")
    try:
        if not GEOPANDAS_AVAILABLE:
            print("âš ï¸  geopandasæœªå®‰è£ï¼Œè·³éåœ°ç†è³‡æ–™")
            return pd.DataFrame()
            
        if not os.path.exists(GEOJSON_PATH):
            print(f"âŒ GeoJSONæª”æ¡ˆæœªæ‰¾åˆ°: {GEOJSON_PATH}")
            return pd.DataFrame()
        
        gdf = gpd.read_file(GEOJSON_PATH)
        
        # å°‹æ‰¾åç¨±æ¬„ä½
        name_column = None
        for col in ['åç¨±', 'name', 'NAME', 'å€åŸŸ', 'å€åŸŸåˆ¥']:
            if col in gdf.columns:
                name_column = col
                break
        
        if name_column is None:
            print("âš ï¸  æœªæ‰¾åˆ°åç¨±æ¬„ä½ï¼Œä½¿ç”¨ç´¢å¼•ä½œç‚ºå€åŸŸåˆ¥")
            gdf['å€åŸŸåˆ¥'] = f"æœªçŸ¥å€åŸŸ_{gdf.index}"
        else:
            gdf['å€åŸŸåˆ¥'] = gdf[name_column].astype(str).str.replace('è‡º', 'å°').str.strip()
            gdf['å€åŸŸåˆ¥'] = gdf['å€åŸŸåˆ¥'].str.replace('æ¡ƒåœ’å¸‚', '').str.strip()
            # ç¢ºä¿å€åŸŸåç¨±ä»¥'å€'çµå°¾
            gdf['å€åŸŸåˆ¥'] = gdf['å€åŸŸåˆ¥'].apply(
                lambda x: x + 'å€' if isinstance(x, str) and x in TAOYUAN_DISTRICTS and not x.endswith('å€') else x
            )
        
        print(f"âœ… æˆåŠŸè¼‰å…¥åœ°ç†è³‡æ–™ï¼Œå½¢ç‹€: {gdf.shape}")
        return gdf
        
    except Exception as e:
        print(f"âŒ è¼‰å…¥åœ°ç†è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return pd.DataFrame()

def load_raw_infrastructure_data():
    """è¼‰å…¥åŸå§‹å…¬å…±å»ºè¨­è³‡æ–™ - åªé€²è¡ŒåŸºæœ¬æ¸…ç†"""
    print("ğŸ“‚ è¼‰å…¥åŸå§‹å…¬å…±å»ºè¨­è³‡æ–™...")
    try:
        if not os.path.exists(PUBLIC_INFRASTRUCTURE_PATH):
            print(f"âŒ å…¬å…±å»ºè¨­è³‡æ–™æª”æ¡ˆæœªæ‰¾åˆ°: {PUBLIC_INFRASTRUCTURE_PATH}")
            return pd.DataFrame()
        
        df_infrastructure = pd.read_excel(PUBLIC_INFRASTRUCTURE_PATH, header=None)
        
        print(f"âœ… æˆåŠŸè¼‰å…¥å…¬å…±å»ºè¨­è³‡æ–™ï¼Œå½¢ç‹€: {df_infrastructure.shape}")
        return df_infrastructure
        
    except Exception as e:
        print(f"âŒ è¼‰å…¥å…¬å…±å»ºè¨­è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return pd.DataFrame()

def load_raw_health_data():
    """è¼‰å…¥åŸå§‹é†«ç™‚è¡›ç”Ÿè³‡æ–™ - åªé€²è¡ŒåŸºæœ¬æ¸…ç†"""
    print("ğŸ“‚ è¼‰å…¥åŸå§‹é†«ç™‚è¡›ç”Ÿè³‡æ–™...")
    try:
        if not os.path.exists(HEALTH_DATA_PATH):
            print(f"âŒ é†«ç™‚è¡›ç”Ÿè³‡æ–™æª”æ¡ˆæœªæ‰¾åˆ°: {HEALTH_DATA_PATH}")
            return pd.DataFrame()
        
        # ç²å–æ‰€æœ‰å·¥ä½œè¡¨
        excel_file = pd.ExcelFile(HEALTH_DATA_PATH)
        health_data = {}
        
        # è¼‰å…¥ä¸»è¦å·¥ä½œè¡¨
        for sheet_name in ['9-1', '9-2']:
            if sheet_name in excel_file.sheet_names:
                health_data[sheet_name] = pd.read_excel(HEALTH_DATA_PATH, sheet_name=sheet_name, header=None)
                print(f"  è¼‰å…¥å·¥ä½œè¡¨ {sheet_name}: {health_data[sheet_name].shape}")
        
        print(f"âœ… æˆåŠŸè¼‰å…¥é†«ç™‚è¡›ç”Ÿè³‡æ–™ï¼ŒåŒ…å« {len(health_data)} å€‹å·¥ä½œè¡¨")
        return health_data
        
    except Exception as e:
        print(f"âŒ è¼‰å…¥é†«ç™‚è¡›ç”Ÿè³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return {}

def save_raw_data():
    """è¼‰å…¥æ‰€æœ‰åŸå§‹æ•¸æ“šä¸¦ä¿å­˜åˆ°è‡¨æ™‚æ–‡ä»¶"""
    print("="*60)
    print("ğŸš€ STEP1: åŸå§‹æ•¸æ“šè¼‰å…¥å™¨")
    print("ğŸ“‹ åŠŸèƒ½: è¼‰å…¥ã€åŸºæœ¬æ¸…ç†ã€ä¿å­˜åŸå§‹æ•¸æ“š")
    print("="*60)
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    os.makedirs('temp_data', exist_ok=True)
    
    raw_data = {}
    
    # è¼‰å…¥å„é¡åŸå§‹æ•¸æ“š
    raw_data['population'] = load_raw_population_data()
    raw_data['commercial'] = load_raw_commercial_data()
    raw_data['income'] = load_raw_income_data()
    raw_data['geo'] = load_raw_geo_data()
    raw_data['infrastructure'] = load_raw_infrastructure_data()
    raw_data['health'] = load_raw_health_data()
    
    # ä¿å­˜éç©ºçš„æ•¸æ“šåˆ°pickleæ–‡ä»¶
    saved_count = 0
    for data_type, data in raw_data.items():
        if isinstance(data, dict):
            # å¥åº·æ•¸æ“šæ˜¯å­—å…¸æ ¼å¼
            if data:
                for sheet_name, sheet_data in data.items():
                    file_path = f'temp_data/raw_{data_type}_{sheet_name}.pkl'
                    sheet_data.to_pickle(file_path)
                    print(f"ğŸ’¾ ä¿å­˜ {data_type}_{sheet_name} åˆ° {file_path}")
                    saved_count += 1
        elif not data.empty:
            file_path = f'temp_data/raw_{data_type}.pkl'
            data.to_pickle(file_path)
            print(f"ğŸ’¾ ä¿å­˜ {data_type} åˆ° {file_path}")
            saved_count += 1
        else:
            print(f"âš ï¸  è·³éç©ºçš„ {data_type} æ•¸æ“š")
    
    print(f"\nâœ… STEP1 å®Œæˆï¼æˆåŠŸä¿å­˜ {saved_count} å€‹åŸå§‹æ•¸æ“šæ–‡ä»¶åˆ° temp_data/ ç›®éŒ„")
    print("ğŸ“Œ ä¸‹ä¸€æ­¥: åŸ·è¡Œ step2_feature_engineering.py é€²è¡Œç‰¹å¾µå·¥ç¨‹")

if __name__ == "__main__":
    save_raw_data() 