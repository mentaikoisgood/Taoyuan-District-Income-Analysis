import pandas as pd
import numpy as np
import os
import json
from datetime import datetime
try:
    import geopandas as gpd
    GEOPANDAS_AVAILABLE = True
except ImportError:
    GEOPANDAS_AVAILABLE = False

# æ¡ƒåœ’å¸‚13å€‹è¡Œæ”¿å€
TAOYUAN_DISTRICTS = [
    'ä¸­å£¢', 'å…«å¾·', 'å¤§åœ’', 'å¤§æºª', 'å¹³é®', 'å¾©èˆˆ', 
    'æ¡ƒåœ’', 'æ–°å±‹', 'æ¥Šæ¢…', 'é¾æ½­', 'é¾œå±±', 'è˜†ç«¹', 'è§€éŸ³'
]

# å¸¸é‡ï¼šåŸºç¤æ¬„ä½åç¨±
POP_TOTAL = 'äººå£_total_population'
POP_WORK_RATIO = 'äººå£_working_age_ratio'
COM_TOTAL_CAP = 'å•†æ¥­_total_capital'
COM_TOTAL_CNT = 'å•†æ¥­_total_companies'
COM_HHI = 'å•†æ¥­_hhi_index'
COM_TERTIARY = 'å•†æ¥­_tertiary_industry_count'
INCOME_MEDIAN = 'æ‰€å¾—_median_household_income'
INCOME_HOUSEHOLDS = 'æ‰€å¾—_total_households'
GEO_AREA = 'åœ°ç†_area_km2'
FACTORY_COUNT = 'å·¥å» _factory_count'
HEALTH_BEDS = 'é†«ç™‚_total_beds'
HEALTH_PERSON = 'é†«ç™‚_medical_personnel_total'
HEALTH_FACILITIES = 'é†«ç™‚_medical_facilities_total'

# è¡ç”Ÿç‰¹å¾µåç¨±
DERIVED_BEDS_PER_1K = 'beds_per_1k_pop'
DERIVED_STAFF_PER_1K = 'med_staff_per_1k_pop'
DERIVED_CAP_PER_HOUSEHOLD = 'capital_per_household'
DERIVED_FACTORIES_PER_1K_WORK = 'factories_per_1k_working_pop'
DERIVED_TERTIARY_RATIO = 'tertiary_industry_ratio'
DERIVED_MED_DENSITY = 'medical_density_area'
DERIVED_ECON_INDEX = 'economic_index'
DERIVED_MED_INDEX = 'medical_index'
DERIVED_AVG_FACTORY_CAP = 'avg_factory_capital'

def clean_numeric_data(series):
    """æ¸…ç†æ•¸å€¼æ•¸æ“šçš„é€šç”¨å‡½æ•¸"""
    return pd.to_numeric(
        series.astype(str)
        .str.replace(',', '')
        .str.replace(' ', '')
        .str.replace('-', '0')
        .str.replace('ï¼', '0'), 
        errors='coerce'
    ).fillna(0)

def create_population_features(raw_population_data):
    """å¾åŸå§‹äººå£æ•¸æ“šå‰µå»ºç‰¹å¾µ - ä¿®æ­£ç‰ˆï¼šæ­£ç¢ºè™•ç†Unnamedæ¬„ä½"""
    print("ğŸ”§ å‰µå»ºäººå£ç‰¹å¾µï¼ˆä¿®æ­£ç‰ˆï¼šåŒ…å«Unnamedæ¬„ä½ï¼‰...")
    
    if raw_population_data.empty:
        print("âš ï¸  åŸå§‹äººå£æ•¸æ“šç‚ºç©ºï¼Œè·³éç‰¹å¾µå‰µå»º")
        return pd.DataFrame()
    
    # å°‹æ‰¾ç¸½è¨ˆæ¬„ä½
    total_col_name = None
    for col in raw_population_data.columns:
        if 'ç¸½' in str(col) and 'è¨ˆ' in str(col):
            total_col_name = col
            break
    
    if total_col_name is None:
        print("âŒ æœªæ‰¾åˆ°ç¸½è¨ˆæ¬„ä½")
        return pd.DataFrame()
    
    print(f"  ğŸ“Š æ‰¾åˆ°ç¸½è¨ˆæ¬„ä½: {total_col_name}")
    
    # ğŸ†• åŸºæ–¼æ•¸å€¼æ¨¡å¼æª¢æ¸¬æ‰€æœ‰å¹´é½¡ç›¸é—œæ¬„ä½ï¼ˆåŒ…æ‹¬Unnamedï¼‰
    exclude_keywords = ['æ€§åˆ¥', 'å€åŸŸä»£ç¢¼', 'å€åŸŸåˆ¥', 'ç¸½', 'è¨ˆ', 'å°è¨ˆ']
    age_numeric_cols = []
    
    # å…ˆå–å¾—æ¨£æœ¬æ•¸æ“šä¾†æ¸¬è©¦æ•¸å€¼æ¬„ä½
    sample_row = raw_population_data[raw_population_data['æ€§åˆ¥'] == 'ç”·'].iloc[0] if len(raw_population_data) > 0 else None
    
    if sample_row is None:
        print("âŒ ç„¡æ³•æ‰¾åˆ°æ¨£æœ¬æ•¸æ“š")
        return pd.DataFrame()
    
    for col in raw_population_data.columns:
        col_str = str(col).strip()
        
        # æ’é™¤éå¹´é½¡æ¬„ä½
        if any(kw in col_str for kw in exclude_keywords):
            continue
        
        # æª¢æ¸¬æ˜¯å¦ç‚ºæ•¸å€¼æ¬„ä½ï¼ˆåŒ…å«å¹´é½¡æ•¸æ“šï¼‰
        try:
            test_val = pd.to_numeric(sample_row[col], errors='coerce')
            if not pd.isna(test_val) and test_val >= 0:  # æœ‰æ•ˆçš„éè² æ•¸å€¼
                age_numeric_cols.append(col)
        except Exception:
            continue
    
    print(f"  ğŸ“ˆ æª¢æ¸¬åˆ° {len(age_numeric_cols)} å€‹æ•¸å€¼å¹´é½¡æ¬„ä½ï¼ˆåŒ…å«Unnamedï¼‰")
    
    # ğŸ†• æ™ºèƒ½ç¢ºå®šå‹å‹•å¹´é½¡æ¬„ä½ç¯„åœï¼ˆ15-64æ­²ï¼‰
    # ç­–ç•¥ï¼šåŸºæ–¼æ¬„ä½ä½ç½®å’Œæ˜ç¢ºå¹´é½¡æ¨™è¨˜ä¾†ä¼°ç®—ç¯„åœ
    
    # æ‰¾åˆ°æ˜ç¢ºçš„å¹´é½¡æ¨™è¨˜æ¬„ä½ä½œç‚ºåƒè€ƒé»
    age_markers = {}
    for i, col in enumerate(age_numeric_cols):
        col_str = str(col)
        if 'ï½' in col_str:
            # æå–å¹´é½¡æ•¸å­—
            import re
            age_match = re.search(r'(\d+)ï½(\d+)', col_str)
            if age_match:
                start_age = int(age_match.group(1))
                end_age = int(age_match.group(2))
                age_markers[i] = (start_age, end_age, col)
    
    print(f"  ğŸ¯ æ‰¾åˆ° {len(age_markers)} å€‹æ˜ç¢ºå¹´é½¡æ¨™è¨˜æ¬„ä½")
    
    # ç¢ºå®šå‹å‹•å¹´é½¡ç¯„åœçš„æ¬„ä½ç´¢å¼•
    working_age_start_idx = None
    working_age_end_idx = None
    
    if age_markers:
        # æ–¹æ³•1ï¼šåŸºæ–¼æ˜ç¢ºæ¨™è¨˜ç¢ºå®šç¯„åœ
        for idx, (start_age, end_age, col) in age_markers.items():
            if start_age == 15:  # æ‰¾åˆ°15æ­²é–‹å§‹çš„æ¬„ä½
                working_age_start_idx = idx
                print(f"    âœ… æ‰¾åˆ°å‹å‹•å¹´é½¡èµ·é»: ç´¢å¼•{idx} ({col})")
                break
        
        for idx, (start_age, end_age, col) in age_markers.items():
            if start_age == 65:  # æ‰¾åˆ°65æ­²é–‹å§‹çš„æ¬„ä½ï¼ˆå‹å‹•å¹´é½¡çµæŸï¼‰
                working_age_end_idx = idx - 1  # 65æ­²ä¹‹å‰çš„æ¬„ä½
                print(f"    âœ… æ‰¾åˆ°å‹å‹•å¹´é½¡çµ‚é»: ç´¢å¼•{working_age_end_idx} (65æ­²å‰)")
                break
    
    # æ–¹æ³•2ï¼šå¦‚æœæ²’æœ‰æ‰¾åˆ°æ˜ç¢ºæ¨™è¨˜ï¼Œä½¿ç”¨ä¼°ç®—
    if working_age_start_idx is None or working_age_end_idx is None:
        print("  âš ï¸  æœªæ‰¾åˆ°æ˜ç¢ºå¹´é½¡æ¨™è¨˜ï¼Œä½¿ç”¨ä¼°ç®—æ–¹æ³•")
        total_age_cols = len(age_numeric_cols)
        
        # ä¼°ç®—ï¼šå‡è¨­0-14æ­²ç´„å å‰15%ï¼Œ65+æ­²ç´„å å¾Œ35%
        estimated_start_idx = int(total_age_cols * 0.15)  # è·³éå‰15%ï¼ˆ0-14æ­²ï¼‰
        estimated_end_idx = int(total_age_cols * 0.65)    # åˆ°65%ä½ç½®ï¼ˆ64æ­²ï¼‰
        
        working_age_start_idx = working_age_start_idx or estimated_start_idx
        working_age_end_idx = working_age_end_idx or estimated_end_idx
        
        print(f"    ğŸ“Š ä¼°ç®—å‹å‹•å¹´é½¡ç¯„åœ: ç´¢å¼• {working_age_start_idx} åˆ° {working_age_end_idx}")
    
    # ç¢ºå®šæœ€çµ‚çš„å‹å‹•å¹´é½¡æ¬„ä½
    working_age_cols = age_numeric_cols[working_age_start_idx:working_age_end_idx+1]
    print(f"  âœ… æœ€çµ‚å‹å‹•å¹´é½¡æ¬„ä½æ•¸é‡: {len(working_age_cols)}")
    print(f"     å‰3å€‹: {working_age_cols[:3]}")
    print(f"     å¾Œ3å€‹: {working_age_cols[-3:]}")
    
    # è¨ˆç®—æ¯å€‹è¡Œæ”¿å€çš„äººå£ç‰¹å¾µ
    population_features = []
    taoyuan_district_names = [name + 'å€' for name in TAOYUAN_DISTRICTS]
    
    print(f"  ğŸ˜ï¸  é–‹å§‹è¨ˆç®—13å€‹è¡Œæ”¿å€çš„äººå£ç‰¹å¾µ...")
    
    for district_name in taoyuan_district_names:
        male_data = raw_population_data[
            (raw_population_data['å€åŸŸåˆ¥'] == district_name) & 
            (raw_population_data['æ€§åˆ¥'] == 'ç”·')
        ]
        female_data = raw_population_data[
            (raw_population_data['å€åŸŸåˆ¥'] == district_name) & 
            (raw_population_data['æ€§åˆ¥'] == 'å¥³')
        ]
        
        if male_data.empty or female_data.empty:
            print(f"    âš ï¸  {district_name} ç¼ºå°‘å®Œæ•´çš„ç”·å¥³æ•¸æ“š")
            continue
        
        # è¨ˆç®—ç¸½äººå£
        male_total = pd.to_numeric(male_data[total_col_name].iloc[0], errors='coerce') or 0
        female_total = pd.to_numeric(female_data[total_col_name].iloc[0], errors='coerce') or 0
        total_population = male_total + female_total
        
        # ğŸ†• è¨ˆç®—å‹å‹•å¹´é½¡äººå£ï¼ˆä½¿ç”¨ä¿®æ­£å¾Œçš„æ¬„ä½åˆ—è¡¨ï¼‰
        male_working_age = 0
        female_working_age = 0
        
        for col in working_age_cols:
            if col in male_data.columns:
                male_val = pd.to_numeric(male_data[col].iloc[0], errors='coerce') or 0
                male_working_age += male_val
            
            if col in female_data.columns:
                female_val = pd.to_numeric(female_data[col].iloc[0], errors='coerce') or 0
                female_working_age += female_val
        
        total_working_age = male_working_age + female_working_age
        working_age_ratio = (total_working_age / total_population * 100) if total_population > 0 else 0
        
        # ğŸ†• æ•¸æ“šé©—è­‰ï¼šæª¢æŸ¥æ¯”ä¾‹æ˜¯å¦åˆç†
        if working_age_ratio < 50 or working_age_ratio > 80:
            print(f"    âš ï¸  {district_name} å‹å‹•å¹´é½¡æ¯”ä¾‹ç•°å¸¸: {working_age_ratio:.1f}%")
        
        population_features.append({
            'å€åŸŸåˆ¥': district_name,
            'total_population': total_population,
            'working_age_ratio': working_age_ratio
        })
        
        # é¡¯ç¤ºè¨ˆç®—è©³æƒ…ï¼ˆåƒ…å‰3å€‹å€åŸŸï¼‰
        if len(population_features) <= 3:
            print(f"    ğŸ“Š {district_name}: ç¸½äººå£ {total_population:,.0f}, å‹å‹•å¹´é½¡ {total_working_age:,.0f}, æ¯”ä¾‹ {working_age_ratio:.1f}%")
    
    df_population = pd.DataFrame(population_features)
    
    # ğŸ†• æœ€çµ‚é©—è­‰å’Œçµ±è¨ˆ
    if not df_population.empty:
        avg_ratio = df_population['working_age_ratio'].mean()
        min_ratio = df_population['working_age_ratio'].min()
        max_ratio = df_population['working_age_ratio'].max()
        
        print(f"  ğŸ“ˆ å‹å‹•å¹´é½¡æ¯”ä¾‹çµ±è¨ˆ:")
        print(f"     å¹³å‡: {avg_ratio:.1f}%")
        print(f"     ç¯„åœ: {min_ratio:.1f}% ~ {max_ratio:.1f}%")
        
        if 60 <= avg_ratio <= 75:
            print(f"  âœ… å¹³å‡æ¯”ä¾‹åœ¨åˆç†ç¯„åœå…§ (60-75%)")
        else:
            print(f"  âš ï¸  å¹³å‡æ¯”ä¾‹è¶…å‡ºé æœŸç¯„åœï¼Œå¯èƒ½éœ€è¦é€²ä¸€æ­¥èª¿æ•´")
    
    print(f"âœ… å‰µå»ºäººå£ç‰¹å¾µå®Œæˆï¼ŒåŒ…å« {len(df_population)} å€‹è¡Œæ”¿å€")
    return df_population

def create_commercial_features(raw_commercial_data):
    """å¾åŸå§‹å•†æ¥­æ•¸æ“šå‰µå»ºç¶œåˆç¶“æ¿ŸæŒ‡æ¨™ç‰¹å¾µ"""
    print("ğŸ”§ å‰µå»ºå•†æ¥­ç‰¹å¾µ...")
    
    if raw_commercial_data.empty:
        print("âš ï¸  åŸå§‹å•†æ¥­æ•¸æ“šç‚ºç©ºï¼Œè·³éç‰¹å¾µå‰µå»º")
        return pd.DataFrame()
    
    # è­˜åˆ¥ç”¢æ¥­æ¬„ä½ - æ’é™¤ç¸½è¨ˆæ¬„ä½é¿å…é‡è¤‡è¨ˆç®—
    exclude_cols = ['å€åŸŸåˆ¥', 'é …ç›®', 'å„è¡Œæ”¿å€åˆè¨ˆå®¶æ•¸åŠè³‡æœ¬é¡']
    
    # å®šç¾©ç”¢æ¥­åˆ†é¡ - ä½¿ç”¨å®Œæ•´æ¬„ä½åç¨±
    primary_industries = ['Aè¾²æ—æ¼ç‰§æ¥­', 'Bç¤¦æ¥­åŠåœŸçŸ³æ¡å–æ¥­']  # ç¬¬ä¸€ç´šç”¢æ¥­
    secondary_industries = ['Cè£½é€ æ¥­', 'Dé›»åŠ›åŠç‡ƒæ°£ä¾›æ‡‰æ¥­', 'Eç”¨æ°´ä¾›æ‡‰åŠæ±¡æŸ“æ•´æ²»æ¥­', 'Fç‡Ÿé€ æ¥­']  # ç¬¬äºŒç´šç”¢æ¥­
    tertiary_industries = ['Gæ‰¹ç™¼åŠé›¶å”®æ¥­', 'Hé‹è¼¸åŠå€‰å„²æ¥­', 'Iä½å®¿åŠé¤é£²æ¥­', 'Jè³‡è¨ŠåŠé€šè¨Šå‚³æ’­æ¥­', 
                          'Ké‡‘èåŠä¿éšªæ¥­', 'Lä¸å‹•ç”¢æ¥­', 'Må°ˆæ¥­ç§‘å­¸åŠæŠ€è¡“æœå‹™æ¥­', 'Næ”¯æ´æœå‹™æ¥­', 
                          'Oå…¬å…±è¡Œæ”¿åŠåœ‹é˜²ï¼›å¼·åˆ¶æ€§ç¤¾æœƒå®‰å…¨', 'Pæ•™è‚²æœå‹™æ¥­', 'Qé†«ç™‚ä¿å¥åŠç¤¾æœƒæœå‹™æ¥­', 
                          'Rè—è¡“å¨›æ¨‚åŠä¼‘é–’æœå‹™æ¥­', 'Så…¶ä»–æœå‹™æ¥­']  # ç¬¬ä¸‰ç´šç”¢æ¥­
    
    # ç¯©é¸æ¡ƒåœ’å¸‚è¡Œæ”¿å€çš„å®¶æ•¸è¡Œ
    taoyuan_count_rows = raw_commercial_data[
        (raw_commercial_data['å€åŸŸåˆ¥'].astype(str).str.contains('æ¡ƒåœ’å¸‚', na=False)) & 
        (raw_commercial_data['é …ç›®'] == 'å®¶æ•¸')
    ]
    
    commercial_features = []
    
    for idx, count_row in taoyuan_count_rows.iterrows():
        # å°æ‡‰çš„è³‡æœ¬é¡è¡Œåœ¨ä¸‹ä¸€è¡Œ
        capital_idx = idx + 1
        if capital_idx < len(raw_commercial_data) and raw_commercial_data.iloc[capital_idx]['é …ç›®'] == 'è³‡æœ¬é¡':
            capital_row = raw_commercial_data.iloc[capital_idx]
        else:
            print(f"âš ï¸  {count_row['å€åŸŸåˆ¥']} ç¼ºå°‘å°æ‡‰çš„è³‡æœ¬é¡è¡Œ")
            continue
        
        # æ¸…ç†å€åŸŸåç¨±
        district_name = count_row['å€åŸŸåˆ¥'].replace('æ¡ƒåœ’å¸‚', '').strip()
        
        # æå–å„ç”¢æ¥­çš„å®¶æ•¸å’Œè³‡æœ¬é¡ - æ’é™¤ç¸½è¨ˆæ¬„ä½
        industry_counts = {}
        industry_capitals = {}
        
        for col in raw_commercial_data.columns:
            if col not in exclude_cols:
                industry_counts[col] = clean_numeric_data(pd.Series([count_row[col]])).iloc[0]
                industry_capitals[col] = clean_numeric_data(pd.Series([capital_row[col]])).iloc[0]
            
        # è¨ˆç®—ç¸½å®¶æ•¸å’Œç¸½è³‡æœ¬é¡
        total_count = sum(industry_counts.values())
        total_capital = sum(industry_capitals.values())
        
        # è¨ˆç®— HHI æŒ‡æ•¸ (Herfindahl Index) - ä¿®æ­£ï¼šä½¿ç”¨è³‡æœ¬ä»½é¡
        hhi = 0
        if total_capital > 0:
            for capital in industry_capitals.values():
                capital_share = capital / total_capital
                hhi += capital_share ** 2
        hhi = hhi * 10000  # è½‰æ›ç‚ºæ¨™æº–çš„ HHI ç¯„åœ (0-10000)
        
        # è¨ˆç®—å„ç´šç”¢æ¥­ç¸½æ•¸ - ä½¿ç”¨å®Œæ•´æ¬„ä½åç¨±ï¼Œæ’é™¤ç¸½è¨ˆæ¬„ä½
        primary_count = 0      # ç¬¬ä¸€ç´šç”¢æ¥­
        secondary_count = 0    # ç¬¬äºŒç´šç”¢æ¥­
        tertiary_count = 0     # ç¬¬ä¸‰ç´šç”¢æ¥­
        
        # ç¬¬ä¸€ç´šç”¢æ¥­ (A, B)
        for col, count in industry_counts.items():
            if col in primary_industries:
                primary_count += count
        
        # ç¬¬äºŒç´šç”¢æ¥­ (C, D, E, F)
        for col, count in industry_counts.items():
            if col in secondary_industries:
                secondary_count += count
        
        # ç¬¬ä¸‰ç´šç”¢æ¥­ (G-S) - ç¢ºä¿ä¸åŒ…å«ç¸½è¨ˆæ¬„ä½
        for col, count in industry_counts.items():
            if col in tertiary_industries:
                tertiary_count += count
        
        # ç§»é™¤ secondary_tertiary_ratio è¨ˆç®—
        # secondary_tertiary_ratio = secondary_count / tertiary_count if tertiary_count > 0 else 0
        
        commercial_features.append({
            'å€åŸŸåˆ¥': district_name,
            'total_companies': total_count,
            'total_capital': total_capital,
            'hhi_index': hhi,
            'tertiary_industry_count': tertiary_count
        })
    
    df_commercial = pd.DataFrame(commercial_features)
    print(f"âœ… å‰µå»ºå•†æ¥­ç‰¹å¾µå®Œæˆï¼ŒåŒ…å« {len(df_commercial)} å€‹è¡Œæ”¿å€")
    print(f"  ğŸ“Š ä½¿ç”¨æ¨™æº–ä¸‰ç´šç”¢æ¥­åˆ†é¡")
    print(f"  ğŸ—‘ï¸ å·²ç§»é™¤ secondary_tertiary_ratio ç‰¹å¾µ")
    print(f"  âš ï¸  æ³¨æ„: æ’é™¤ 'å„è¡Œæ”¿å€åˆè¨ˆå®¶æ•¸åŠè³‡æœ¬é¡' æ¬„ä½é¿å…é‡è¤‡è¨ˆç®—")
    print(f"  âš ï¸  ä½¿ç”¨å®Œæ•´æ¬„ä½åç¨±é€²è¡Œç”¢æ¥­åˆ†é¡")
    return df_commercial

def create_income_features(raw_income_data):
    """å¾åŸå§‹æ‰€å¾—æ•¸æ“šå‰µå»ºç‰¹å¾µ"""
    print("ğŸ”§ å‰µå»ºæ‰€å¾—ç‰¹å¾µ...")
    
    if raw_income_data.empty:
        print("âš ï¸  åŸå§‹æ‰€å¾—æ•¸æ“šç‚ºç©ºï¼Œè·³éç‰¹å¾µå‰µå»º")
        return pd.DataFrame()
    
    # è½‰æ›ä¸­ä½æ•¸ç‚ºå…ƒï¼ˆåŸæœ¬æ˜¯åƒå…ƒå–®ä½ï¼‰
    raw_income_data['median_income_yuan'] = raw_income_data['ä¸­ä½æ•¸'] * 1000
    
    # æŒ‰å€åŸŸèšåˆï¼Œè¨ˆç®—ä¸­ä½æ•¸æ‰€å¾—
    def weighted_median(group):
        """è¨ˆç®—åŠ æ¬Šä¸­ä½æ•¸ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        total_households = group['ç´ç¨…å–®ä½(æˆ¶)'].sum()
        if total_households == 0:
            print(f"      âš ï¸  è©²å€æˆ¶æ•¸ç¸½å’Œç‚º0ï¼Œè¿”å›NaN")
            return np.nan  # æ›´æ”¹ï¼šæˆ¶æ•¸ç‚º0æ™‚è¿”å›NaNè€Œé0
        
        # æŒ‰æ”¶å…¥æ°´æº–æ’åº
        sorted_group = group.sort_values('median_income_yuan')
        
        # è¨ˆç®—ç´¯ç©æˆ¶æ•¸æ¯”ä¾‹
        sorted_group = sorted_group.copy()
        sorted_group['cumulative_households'] = sorted_group['ç´ç¨…å–®ä½(æˆ¶)'].cumsum()
        sorted_group['cumulative_ratio'] = sorted_group['cumulative_households'] / total_households
        
        # æ‰¾åˆ°ä¸­ä½æ•¸ä½ç½®ï¼ˆ50%ï¼‰
        median_idx = sorted_group[sorted_group['cumulative_ratio'] >= 0.5].index[0]
        return sorted_group.loc[median_idx, 'median_income_yuan']
    
    income_features = []
    for district, group in raw_income_data.groupby('å€åŸŸåˆ¥'):
        median_income = weighted_median(group)
        total_households = group['ç´ç¨…å–®ä½(æˆ¶)'].sum()
        income_features.append({
            'å€åŸŸåˆ¥': district,
            'median_household_income': median_income,
            'total_households': total_households
        })
    
    df_income = pd.DataFrame(income_features)
    print(f"âœ… å‰µå»ºæ‰€å¾—ç‰¹å¾µå®Œæˆï¼ŒåŒ…å« {len(df_income)} å€‹è¡Œæ”¿å€")
    return df_income

def create_geo_features(raw_geo_data):
    """å¾åŸå§‹åœ°ç†æ•¸æ“šå‰µå»ºç‰¹å¾µ"""
    print("ğŸ”§ å‰µå»ºåœ°ç†ç‰¹å¾µ...")
    
    if not GEOPANDAS_AVAILABLE or raw_geo_data.empty:
        print("âš ï¸  åœ°ç†æ•¸æ“šä¸å¯ç”¨ï¼Œè·³éç‰¹å¾µå‰µå»º")
        return pd.DataFrame()
    
    # æ”¹å–„åº§æ¨™ç³»çµ±æª¢æ¸¬å’Œè½‰æ›
    try:
        # æª¢æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„CRS
        if raw_geo_data.crs is None:
            print("  âš ï¸  åœ°ç†æ•¸æ“šç¼ºå°‘åº§æ¨™åƒè€ƒç³»çµ±(CRS)ï¼Œå‡è¨­ç‚ºWGS84")
            raw_geo_data = raw_geo_data.set_crs('EPSG:4326')
        
        # è½‰æ›åˆ°é©åˆå°ç£çš„åº§æ¨™ç³»çµ±ï¼ˆTWD97 TM2ï¼‰
        if str(raw_geo_data.crs) != 'EPSG:3826':
            raw_geo_data = raw_geo_data.to_crs('EPSG:3826')
            print("  âœ… åº§æ¨™ç³»çµ±è½‰æ›è‡³ TWD97 TM2 (EPSG:3826)")
    
        # è¨ˆç®—é¢ç©ï¼ˆå¹³æ–¹å…¬å°ºè½‰å¹³æ–¹å…¬é‡Œï¼‰
        raw_geo_data['area_km2'] = raw_geo_data.geometry.area / 1e6
        
    except Exception as e:
        print(f"  âš ï¸  åº§æ¨™ç³»çµ±è™•ç†å‡ºéŒ¯: {e}")
        # å˜—è©¦ç›´æ¥è¨ˆç®—é¢ç©
        try:
            raw_geo_data['area_km2'] = raw_geo_data.geometry.area / 1e6
        except Exception:
            print("  âŒ ç„¡æ³•è¨ˆç®—é¢ç©ï¼Œè¿”å›ç©ºç‰¹å¾µ")
            return pd.DataFrame()
    
    # è½‰æ›ç‚ºæ™®é€šDataFrame
    geo_features = []
    for idx, row in raw_geo_data.iterrows():
        geo_features.append({
            'å€åŸŸåˆ¥': row['å€åŸŸåˆ¥'],
            'area_km2': row['area_km2']
        })
    
    df_geo = pd.DataFrame(geo_features)
    print(f"âœ… å‰µå»ºåœ°ç†ç‰¹å¾µå®Œæˆï¼ŒåŒ…å« {len(df_geo)} å€‹è¡Œæ”¿å€")
    return df_geo

def create_infrastructure_features(raw_infrastructure_data):
    """å¾åŸå§‹å…¬å…±å»ºè¨­æ•¸æ“šå‰µå»ºç‰¹å¾µ"""
    print("ğŸ”§ å‰µå»ºå·¥å» ç‰¹å¾µ...")
    
    if raw_infrastructure_data.empty:
        print("âš ï¸  åŸå§‹å…¬å…±å»ºè¨­æ•¸æ“šç‚ºç©ºï¼Œè·³éç‰¹å¾µå‰µå»º")
        return pd.DataFrame()
    
    # å‹•æ…‹æœå°‹æ•¸æ“šèµ·å§‹è¡Œ - æ”¹å–„æª¢æ¸¬é‚è¼¯
    taoyuan_districts = [name + 'å€' for name in TAOYUAN_DISTRICTS]
    start_row = None
    
    for i in range(min(50, len(raw_infrastructure_data))):  # é™åˆ¶æœå°‹ç¯„åœé¿å…èª¤åˆ¤
        if raw_infrastructure_data.iloc[i, 0] is not None:
            cell_value = str(raw_infrastructure_data.iloc[i, 0]).strip()
            
            # æ›´åš´æ ¼çš„è¡Œæ”¿å€æª¢æ¸¬æ¢ä»¶
            contains_district = any(district in cell_value for district in taoyuan_districts)
            
            # æª¢æŸ¥ç¬¬äºŒæ¬„æ˜¯å¦ç‚ºæœ‰æ•ˆæ•¸å­—ï¼ˆé0ä¸”éç©ºï¼‰
            try:
                second_col_value = pd.to_numeric(raw_infrastructure_data.iloc[i, 1], errors='coerce')
                is_valid_number = (second_col_value is not None and 
                                 not pd.isna(second_col_value) and 
                                 second_col_value >= 0)
            except:
                is_valid_number = False
            
            # é¿å…æ¨™é¡Œè¡Œï¼šæª¢æŸ¥æ˜¯å¦åŒ…å«æ˜é¡¯çš„æ¨™é¡Œé—œéµå­—
            title_keywords = ['åˆè¨ˆ', 'ç¸½è¨ˆ', 'å°è¨ˆ', 'é …ç›®', 'èªªæ˜', 'å‚™è¨»']
            is_title_row = any(keyword in cell_value for keyword in title_keywords)
            
            # ç¢ºä¿è¡Œæ”¿å€åç¨±çš„å®Œæ•´æ€§ï¼ˆé¿å…éƒ¨åˆ†åŒ¹é…ï¼‰
            exact_district_match = cell_value in taoyuan_districts or any(
                cell_value.endswith(district) for district in taoyuan_districts
            )
            
            if exact_district_match and is_valid_number and not is_title_row:
                start_row = i
                break
    
    if start_row is None:
        print("âŒ ç„¡æ³•æ‰¾åˆ°åŒ…å«è¡Œæ”¿å€æ•¸æ“šçš„èµ·å§‹è¡Œ")
        return pd.DataFrame()
    
    # æå–13å€‹è¡Œæ”¿å€è³‡æ–™ï¼Œåªè¦å€åŸŸåˆ¥å’Œç¸½è¨ˆæ¬„ä½
    district_data = raw_infrastructure_data.iloc[start_row:start_row+13, [0, 1]].copy()
    district_data.columns = ['å€åŸŸåˆ¥', 'factory_count']
    
    # æ¸…ç†å€åŸŸåç¨±
    district_data['å€åŸŸåˆ¥'] = district_data['å€åŸŸåˆ¥'].astype(str).str.strip()
    district_data['å€åŸŸåˆ¥'] = district_data['å€åŸŸåˆ¥'].str.replace('\u3000', '').str.replace('ã€€', '')
    district_data['å€åŸŸåˆ¥'] = district_data['å€åŸŸåˆ¥'].str.extract(r'([^A-Za-z\s]+)')[0]
    district_data['å€åŸŸåˆ¥'] = district_data['å€åŸŸåˆ¥'].str.strip()
    
    # ç¯©é¸æœ‰æ•ˆçš„è¡Œæ”¿å€
    valid_district_names = [name if name.endswith('å€') else name + 'å€' for name in TAOYUAN_DISTRICTS]
    district_data = district_data[district_data['å€åŸŸåˆ¥'].isin(valid_district_names)].copy()
    
    # æ¸…ç†æ•¸å€¼æ•¸æ“š
    district_data['factory_count'] = clean_numeric_data(district_data['factory_count'])
    
    print(f"âœ… å‰µå»ºå·¥å» ç‰¹å¾µå®Œæˆï¼ŒåŒ…å« {len(district_data)} å€‹è¡Œæ”¿å€")
    return district_data

def create_health_features(raw_health_data):
    """å¾åŸå§‹é†«ç™‚è¡›ç”Ÿæ•¸æ“šå‰µå»ºç‰¹å¾µ"""
    print("ğŸ”§ å‰µå»ºé†«ç™‚è¡›ç”Ÿç‰¹å¾µ...")
    
    if not raw_health_data:
        print("âš ï¸  åŸå§‹é†«ç™‚è¡›ç”Ÿæ•¸æ“šç‚ºç©ºï¼Œè·³éç‰¹å¾µå‰µå»º")
        return pd.DataFrame()
    
    taoyuan_districts = [name + 'å€' for name in TAOYUAN_DISTRICTS]
    health_features = []
    
    # è™•ç†è¡¨ 9-1ï¼šé†«äº‹äººå“¡ç¸½è¨ˆ
    medical_personnel_data = None
    if '9-1' in raw_health_data:
        df_91 = raw_health_data['9-1']
        personnel_rows = []
        for i in range(len(df_91)):
            if df_91.iloc[i, 0] is not None:
                cell_value = str(df_91.iloc[i, 0]).strip()
                if any(district in cell_value for district in taoyuan_districts):
                    personnel_rows.append(i)
        
        if personnel_rows:
            medical_personnel_data = df_91.iloc[personnel_rows, [0, 1]].copy()
            medical_personnel_data.columns = ['å€åŸŸåˆ¥', 'medical_personnel_total']
    
    # è™•ç†è¡¨ 9-2ï¼šé†«ç™‚é™¢æ‰€ç¸½æ•¸å’Œç¸½ç—…åºŠæ•¸
    medical_facility_data = None
    if '9-2' in raw_health_data:
        df_92 = raw_health_data['9-2']
        facility_rows = []
        for i in range(len(df_92)):
            if df_92.iloc[i, 0] is not None:
                cell_value = str(df_92.iloc[i, 0]).strip()
                if any(district in cell_value for district in taoyuan_districts):
                    facility_rows.append(i)
        
        if facility_rows:
            medical_facility_data = df_92.iloc[facility_rows, [0, 1, 4]].copy()
            medical_facility_data.columns = ['å€åŸŸåˆ¥', 'medical_facilities_total', 'total_beds']
    
    # åˆä½µé†«ç™‚æ•¸æ“š
    if medical_personnel_data is not None and medical_facility_data is not None:
        # æ¸…ç†å€åŸŸåç¨±
        for df in [medical_personnel_data, medical_facility_data]:
            df['å€åŸŸåˆ¥'] = df['å€åŸŸåˆ¥'].astype(str).str.strip()
            df['å€åŸŸåˆ¥'] = df['å€åŸŸåˆ¥'].str.extract(r'([^A-Za-z\s]+)')[0]
            df['å€åŸŸåˆ¥'] = df['å€åŸŸåˆ¥'].str.replace('   ', '').str.strip()
        
        # åˆä½µå…©å€‹è¡¨
        combined_health_data = pd.merge(medical_personnel_data, medical_facility_data, on='å€åŸŸåˆ¥', how='outer')
        
        # æ¸…ç†æ•¸å€¼æ•¸æ“š
        numeric_cols = ['medical_personnel_total', 'medical_facilities_total', 'total_beds']
        for col in numeric_cols:
            if col in combined_health_data.columns:
                combined_health_data[col] = clean_numeric_data(combined_health_data[col])
        
        print(f"âœ… å‰µå»ºé†«ç™‚è¡›ç”Ÿç‰¹å¾µå®Œæˆï¼ŒåŒ…å« {len(combined_health_data)} å€‹è¡Œæ”¿å€")
        return combined_health_data
    
    print("âŒ ç„¡æ³•å‰µå»ºé†«ç™‚è¡›ç”Ÿç‰¹å¾µ")
    return pd.DataFrame()

def standardize_column_names(df, source_name):
    """çµ±ä¸€æ¬„åå‘½åè¦æ ¼ï¼šä¾†æº_æŒ‡æ¨™"""
    new_columns = {}
    for col in df.columns:
        if col == 'å€åŸŸåˆ¥':
            new_columns[col] = col  # ä¿æŒå€åŸŸåˆ¥ä¸è®Š
        else:
            # æ¸…ç†æ¬„ä½åç¨±ä¸­çš„ç‰¹æ®Šå­—ç¬¦å’Œç©ºæ ¼
            clean_col = str(col).strip().replace(' ', '').replace('ã€€', '').replace('\u3000', '')
            new_columns[col] = f"{source_name}_{clean_col}"
    
    df_renamed = df.rename(columns=new_columns)
    print(f"  æ¨™æº–åŒ– {source_name} æ¬„ä½åç¨±ï¼Œå…± {len(new_columns)-1} å€‹ç‰¹å¾µ")
    return df_renamed

def ensure_numeric_types(df, exclude_cols=['å€åŸŸåˆ¥']):
    """ç¢ºä¿æ‰€æœ‰æ•¸å€¼æ¬„ä½éƒ½è½‰æ›ç‚ºé©ç•¶çš„æ•¸å€¼é¡å‹"""
    for col in df.columns:
        if col not in exclude_cols:
            # è½‰æ›ç‚ºæ•¸å€¼ï¼Œç„¡æ³•è½‰æ›çš„è¨­ç‚º0
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            
            # å¦‚æœæ˜¯æ•´æ•¸ï¼Œè½‰ç‚ºint64ï¼Œå¦å‰‡ä¿æŒfloat64
            if df[col].dtype == 'float64' and (df[col] % 1 == 0).all():
                df[col] = df[col].astype('int64')
            else:
                df[col] = df[col].astype('float64')
    
    return df

def load_raw_data():
    """è¼‰å…¥æ‰€æœ‰åŸå§‹æ•¸æ“š"""
    print("ğŸ“‚ è¼‰å…¥åŸå§‹æ•¸æ“šæ–‡ä»¶...")
    
    raw_data = {}
    
    # è¼‰å…¥å„é¡åŸå§‹æ•¸æ“š
    if os.path.exists('temp_data/raw_population.pkl'):
        raw_data['population'] = pd.read_pickle('temp_data/raw_population.pkl')
        print("  âœ… è¼‰å…¥äººå£æ•¸æ“š")
    
    if os.path.exists('temp_data/raw_commercial.pkl'):
        raw_data['commercial'] = pd.read_pickle('temp_data/raw_commercial.pkl')
        print("  âœ… è¼‰å…¥å•†æ¥­æ•¸æ“š")
    
    if os.path.exists('temp_data/raw_income.pkl'):
        raw_data['income'] = pd.read_pickle('temp_data/raw_income.pkl')
        print("  âœ… è¼‰å…¥æ‰€å¾—æ•¸æ“š")
    
    if os.path.exists('temp_data/raw_geo.pkl'):
        raw_data['geo'] = pd.read_pickle('temp_data/raw_geo.pkl')
        print("  âœ… è¼‰å…¥åœ°ç†æ•¸æ“š")
    
    if os.path.exists('temp_data/raw_infrastructure.pkl'):
        raw_data['infrastructure'] = pd.read_pickle('temp_data/raw_infrastructure.pkl')
        print("  âœ… è¼‰å…¥å…¬å…±å»ºè¨­æ•¸æ“š")
    
    # è¼‰å…¥é†«ç™‚è¡›ç”Ÿæ•¸æ“š
    health_data = {}
    for sheet in ['9-1', '9-2']:
        file_path = f'temp_data/raw_health_{sheet}.pkl'
        if os.path.exists(file_path):
            health_data[sheet] = pd.read_pickle(file_path)
    
    if health_data:
        raw_data['health'] = health_data
        print("  âœ… è¼‰å…¥é†«ç™‚è¡›ç”Ÿæ•¸æ“š")
    
    return raw_data

def create_all_features():
    """åŸ·è¡Œå®Œæ•´çš„ç‰¹å¾µå·¥ç¨‹æµç¨‹"""
    print("="*60)
    print("ğŸš€ STEP2: ç‰¹å¾µå·¥ç¨‹")
    print("ğŸ“‹ åŠŸèƒ½: å¾åŸå§‹æ•¸æ“šå‰µå»ºã€æ¨™æº–åŒ–ã€åˆä½µç‰¹å¾µ")
    print("="*60)
    
    # æª¢æŸ¥æ˜¯å¦æœ‰åŸå§‹æ•¸æ“š
    if not os.path.exists('temp_data'):
        print("âŒ æ‰¾ä¸åˆ° temp_data ç›®éŒ„")
        print("ğŸ“Œ è«‹å…ˆåŸ·è¡Œ step1_raw_data_loader.py")
        return
    
    # è¼‰å…¥åŸå§‹æ•¸æ“š
    raw_data = load_raw_data()
    
    if not raw_data:
        print("âŒ æœªè¼‰å…¥ä»»ä½•åŸå§‹æ•¸æ“š")
        return
    
    # å‰µå»ºå„é¡ç‰¹å¾µ
    feature_datasets = {}
    
    if 'population' in raw_data:
        feature_datasets['äººå£'] = create_population_features(raw_data['population'])
    
    if 'commercial' in raw_data:
        feature_datasets['å•†æ¥­'] = create_commercial_features(raw_data['commercial'])
    
    if 'income' in raw_data:
        feature_datasets['æ‰€å¾—'] = create_income_features(raw_data['income'])
    
    if 'geo' in raw_data:
        feature_datasets['åœ°ç†'] = create_geo_features(raw_data['geo'])
    
    if 'infrastructure' in raw_data:
        feature_datasets['å·¥å» '] = create_infrastructure_features(raw_data['infrastructure'])
    
    if 'health' in raw_data:
        feature_datasets['é†«ç™‚'] = create_health_features(raw_data['health'])
    
    # æ¨™æº–åŒ–æ¬„ä½åç¨±
    print("\nğŸ·ï¸  æ¨™æº–åŒ–æ¬„ä½åç¨±...")
    for source_name, df in feature_datasets.items():
        if not df.empty:
            feature_datasets[source_name] = standardize_column_names(df, source_name)
    
    # åˆä½µæ‰€æœ‰ç‰¹å¾µ
    print("\nğŸ”— åˆä½µæ‰€æœ‰ç‰¹å¾µ...")
    valid_datasets = {name: df for name, df in feature_datasets.items() if not df.empty}
    
    if not valid_datasets:
        print("âŒ æ²’æœ‰æœ‰æ•ˆçš„ç‰¹å¾µæ•¸æ“šé›†")
        return
    
    # å¾ç¬¬ä¸€å€‹æ•¸æ“šé›†é–‹å§‹åˆä½µ
    first_dataset_name = list(valid_datasets.keys())[0]
    merged_df = valid_datasets[first_dataset_name].copy()
    merge_info = {first_dataset_name: f"{merged_df.shape[1]-1} å€‹ç‰¹å¾µ"}
    
    print(f"  åŸºæº–æ•¸æ“šé›†: {first_dataset_name}")
    
    # é€å€‹åˆä½µå…¶ä»–æ•¸æ“šé›†
    for name, df in list(valid_datasets.items())[1:]:
        print(f"  åˆä½µ {name} ç‰¹å¾µ...")
        before_cols = merged_df.shape[1]
        merged_df = pd.merge(merged_df, df, on='å€åŸŸåˆ¥', how='left')
        after_cols = merged_df.shape[1]
        added_cols = after_cols - before_cols
        merge_info[name] = f"{added_cols} å€‹ç‰¹å¾µ"
        print(f"    æ–°å¢ {added_cols} å€‹ç‰¹å¾µ")
    
    # ç¢ºä¿æ•¸å€¼é¡å‹
    print("\nğŸ”¢ ç¢ºä¿æ•¸å€¼é¡å‹...")
    merged_df = ensure_numeric_types(merged_df)
    
    # ç”Ÿæˆmetadata
    print("\nğŸ“ ç”Ÿæˆmetadata...")
    metadata = {
        "dataset_info": {
            "name": "æ¡ƒåœ’å¸‚è¡Œæ”¿å€ç™¼å±•ç‰¹å¾µè³‡æ–™",
            "description": "æ¡ƒåœ’å¸‚13å€‹è¡Œæ”¿å€çš„äººå£ã€å•†æ¥­ã€æ‰€å¾—ã€åœ°ç†ã€å…¬å…±å»ºè¨­ã€é†«ç™‚ç­‰ç‰¹å¾µè³‡æ–™",
            "year": 110,
            "last_updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "total_districts": len(merged_df),
            "total_features": merged_df.shape[1] - 1
        },
        "districts": sorted(merged_df['å€åŸŸåˆ¥'].tolist()),
        "data_sources": merge_info,
        "features": {}
    }
    
    # ç‚ºæ¯å€‹ç‰¹å¾µç”Ÿæˆæè¿°
    for col in merged_df.columns:
        if col != 'å€åŸŸåˆ¥':
            if '_' in col:
                source, indicator = col.split('_', 1)
                metadata["features"][col] = {
                    "source": source,
                    "indicator": indicator,
                    "data_type": str(merged_df[col].dtype),
                    "min_value": float(merged_df[col].min()),
                    "max_value": float(merged_df[col].max()),
                    "mean_value": float(merged_df[col].mean()),
                    "missing_count": int(merged_df[col].isnull().sum())
                }
    
    # ä¿å­˜çµæœ
    print("\nğŸ’¾ ä¿å­˜çµæœ...")
    os.makedirs('output', exist_ok=True)
    
    # ä¿å­˜ç‰¹å¾µCSV
    csv_path = 'output/taoyuan_features_numeric.csv'
    merged_df.to_csv(csv_path, index=False, encoding='utf-8')
    print(f"  ç‰¹å¾µè³‡æ–™å·²ä¿å­˜è‡³: {csv_path}")
    
    # ä¿å­˜metadata JSON
    json_path = 'output/taoyuan_meta.json'
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    print(f"  Metadataå·²ä¿å­˜è‡³: {json_path}")
    
    # è¼¸å‡ºæœ€çµ‚çµ±è¨ˆ
    print(f"\nâœ… STEP2 å®Œæˆï¼")
    print(f"ğŸ“Š æœ€çµ‚çµ±è¨ˆ:")
    print(f"  è¡Œæ”¿å€æ•¸é‡: {len(merged_df)}")
    print(f"  ç‰¹å¾µæ•¸é‡: {merged_df.shape[1]-1}")
    print(f"  è³‡æ–™ä¾†æº: {len(valid_datasets)} å€‹")
    print(f"  ç¼ºå¤±å€¼: {merged_df.isnull().sum().sum()} å€‹")
    
    # æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§
    if merged_df.isnull().sum().sum() == 0:
        print("  âœ… æ•¸æ“šå®Œæ•´ï¼Œç„¡ç¼ºå¤±å€¼")
    else:
        print("  âš ï¸  å­˜åœ¨ç¼ºå¤±å€¼ï¼Œè«‹æª¢æŸ¥")

    # ä¹ã€ç¼ºå¤±å€¼è™•ç†ç­–ç•¥
    print("\nğŸ”§ ä¹ã€ç¼ºå¤±å€¼è™•ç†ç­–ç•¥")
    
    missing_count = merged_df.isnull().sum().sum()
    if missing_count > 0:
        print(f"  ç™¼ç¾ {missing_count} å€‹ç¼ºå¤±å€¼")
        
        # æª¢æŸ¥econ_to_med_ratioçš„ç¼ºå¤±å€¼
        if DERIVED_ECON_MED_RATIO in merged_df.columns and merged_df[DERIVED_ECON_MED_RATIO].isnull().any():
            missing_districts = merged_df[merged_df[DERIVED_ECON_MED_RATIO].isnull()]['å€åŸŸåˆ¥'].values
            print(f"  ğŸ“ {DERIVED_ECON_MED_RATIO} ç¼ºå¤±å€¼è¡Œæ”¿å€: {', '.join(missing_districts)}")
            
            # æä¾›å¤šç¨®è™•ç†ç­–ç•¥
            print("  ğŸ’¡ è™•ç†ç­–ç•¥é¸é …:")
            print("     1. è¨­ç‚ºæ¥µå¤§å€¼ (è¡¨ç¤ºé†«ç™‚è³‡æºç¨€ç¼º)")
            print("     2. è¨­ç‚ºç¶“æ¿ŸæŒ‡æ•¸å€¼ (ä¿å®ˆä¼°è¨ˆ)")
            print("     3. ä½¿ç”¨å…¶ä»–è¡Œæ”¿å€ä¸­ä½æ•¸")
            print("     4. ä¿ç•™NaN (åˆ†ææ™‚æ’é™¤)")
            
            # ç­–ç•¥1: è¨­ç‚ºæ¥µå¤§å€¼ (æ¨è–¦ç”¨æ–¼è©²å ´æ™¯)
            max_ratio = merged_df[DERIVED_ECON_MED_RATIO].max()
            merged_df[DERIVED_ECON_MED_RATIO] = merged_df[DERIVED_ECON_MED_RATIO].fillna(max_ratio * 2)
            print(f"  âœ… æ¡ç”¨ç­–ç•¥1: è¨­ç‚º {max_ratio * 2:.1f} (è¡¨ç¤ºé†«ç™‚è³‡æºæ¥µåº¦ç¨€ç¼º)")
            
        print(f"  âœ… è™•ç†å¾Œç¼ºå¤±å€¼æ•¸é‡: {merged_df.isnull().sum().sum()}")
    else:
        print("  âœ… ç„¡ç¼ºå¤±å€¼")
    
    # ä½¿ç”¨æ•¸å€¼ç‰¹å¾µï¼ˆæ’é™¤å€åŸŸåˆ¥ï¼‰
    X = merged_df.drop(columns=['å€åŸŸåˆ¥']).fillna(0)

def enhanced_feature_engineering():
    """å¢å¼·ç‰ˆç‰¹å¾µå·¥ç¨‹ï¼šç°¡åŒ–ç‰ˆ"""
    print("="*80)
    print("ğŸ”¬ é–‹å§‹å¢å¼·ç‰ˆç‰¹å¾µå·¥ç¨‹")
    print("="*80)
    
    # è¼‰å…¥åŸºç¤ç‰¹å¾µ
    df = pd.read_csv('output/taoyuan_features_numeric.csv')
    print(f"ğŸ“‚ è¼‰å…¥åŸºç¤ç‰¹å¾µæ•¸æ“š: {df.shape[0]} è¡Œ {df.shape[1]} åˆ—")
    
    # ç¢ºèªè¡Œæ”¿å€æ•¸é‡
    district_count = len(df)
    assert district_count == 13, f"æ‡‰æœ‰13å€‹è¡Œæ”¿å€ï¼Œå¯¦éš›æœ‰ {district_count} å€‹"
    print(f"  âœ… ç¢ºèª13å€‹è¡Œæ”¿å€: {', '.join(df['å€åŸŸåˆ¥'].tolist())}")
    
    # å‰µå»ºå¯†åº¦èˆ‡äººå‡ç‰¹å¾µ
    print("\nğŸ—ï¸ å‰µå»ºç‰¹å¾µ...")
    
    if 'åœ°ç†_area_km2' in df.columns:
        # æ¯åƒäººç‰¹å¾µ
        if HEALTH_BEDS in df.columns and POP_TOTAL in df.columns:
            df[DERIVED_BEDS_PER_1K] = df[HEALTH_BEDS] / (df[POP_TOTAL] / 1000)
            print("  âœ… æ¯åƒäººç—…åºŠæ•¸")
        
        if HEALTH_PERSON in df.columns and POP_TOTAL in df.columns:
            df[DERIVED_STAFF_PER_1K] = df[HEALTH_PERSON] / (df[POP_TOTAL] / 1000)
            print("  âœ… æ¯åƒäººé†«ç™‚äººå“¡æ•¸")
        
        # äººå‡ç‰¹å¾µ
        if COM_TOTAL_CAP in df.columns and INCOME_HOUSEHOLDS in df.columns:
            df[DERIVED_CAP_PER_HOUSEHOLD] = df[COM_TOTAL_CAP] / df[INCOME_HOUSEHOLDS]
            print("  âœ… è³‡æœ¬é¡/æˆ¶")
        
        # å‹å‹•åŠ›ç›¸é—œç‰¹å¾µ
        if POP_WORK_RATIO in df.columns and FACTORY_COUNT in df.columns and POP_TOTAL in df.columns:
            working_age_population = df[POP_TOTAL] * (df[POP_WORK_RATIO] / 100)
            df[DERIVED_FACTORIES_PER_1K_WORK] = df[FACTORY_COUNT] / (working_age_population / 1000)
            print("  âœ… æ¯åƒå‹å‹•äººå£å·¥å» æ•¸")
        
        # ç”¢æ¥­çµæ§‹ç‰¹å¾µ
        if COM_TERTIARY in df.columns and COM_TOTAL_CNT in df.columns:
            df[DERIVED_TERTIARY_RATIO] = df[COM_TERTIARY] / df[COM_TOTAL_CNT] * 100
            print("  âœ… ç¬¬ä¸‰ç´šç”¢æ¥­å æ¯”")
        
        # é†«ç™‚å¯†åº¦
        if HEALTH_FACILITIES in df.columns:
            df[DERIVED_MED_DENSITY] = df[HEALTH_FACILITIES] / df[GEO_AREA]
            print("  âœ… é†«ç™‚å¯†åº¦")
    
    # å‰µå»ºç¶œåˆæŒ‡æ•¸
    print("\nğŸ¯ å‰µå»ºç¶œåˆæŒ‡æ•¸...")
    
    from sklearn.preprocessing import StandardScaler
    
    # ç¶“æ¿Ÿç™¼å±•æŒ‡æ•¸
    economic_cols = [col for col in [COM_TOTAL_CNT, COM_TOTAL_CAP] if col in df.columns]
    if len(economic_cols) >= 2:
        economic_data = df[economic_cols].fillna(0)
        econ_scaler = StandardScaler()
        economic_scaled = econ_scaler.fit_transform(economic_data)
        df[DERIVED_ECON_INDEX] = np.mean(economic_scaled, axis=1)
        print(f"  âœ… ç¶“æ¿Ÿç™¼å±•æŒ‡æ•¸")
    
    # ğŸ†• é†«ç™‚æœå‹™å­æŒ‡æ¨™ - æ–¹æ¡ˆA: ä¿æŒåŸå§‹æ•¸æ“šåˆ°STEP3
    medical_cols = [col for col in [DERIVED_BEDS_PER_1K, DERIVED_STAFF_PER_1K, DERIVED_MED_DENSITY] if col in df.columns]
    if len(medical_cols) >= 3:
        print(f"  ğŸ“Š é†«ç™‚å­æŒ‡æ¨™æ•¸é‡: {len(medical_cols)}")
        
        # ğŸ”„ æ–¹æ¡ˆA: ä¿ç•™åŸå§‹é†«ç™‚å­æŒ‡æ¨™ï¼Œä¸é€²è¡Œæ¨™æº–åŒ–
        # é‡å‘½åç‚ºæ›´ç°¡æ½”çš„åç¨±ï¼Œä¾›STEP3ä½¿ç”¨
        df['medical_beds_per_1k'] = df[DERIVED_BEDS_PER_1K]
        df['medical_staff_per_1k'] = df[DERIVED_STAFF_PER_1K] 
        df['medical_facility_density'] = df[DERIVED_MED_DENSITY]
        
        print(f"  âœ… ä¿ç•™é†«ç™‚å­æŒ‡æ¨™åŸå§‹æ•¸æ“š (æ–¹æ¡ˆAçµ±ä¸€Z-scoreç­–ç•¥)")
        print(f"    é†«ç™‚åºŠä½å¯†åº¦ç¯„åœ: {df['medical_beds_per_1k'].min():.2f} - {df['medical_beds_per_1k'].max():.2f}")
        print(f"    é†«ç™‚äººå“¡å¯†åº¦ç¯„åœ: {df['medical_staff_per_1k'].min():.2f} - {df['medical_staff_per_1k'].max():.2f}")
        print(f"    é†«ç™‚è¨­æ–½å¯†åº¦ç¯„åœ: {df['medical_facility_density'].min():.4f} - {df['medical_facility_density'].max():.4f}")
        print(f"    âš¡ é€™äº›æŒ‡æ¨™å°‡åœ¨STEP3é€²è¡Œçµ±ä¸€Z-scoreæ¨™æº–åŒ–")
    else:
        print(f"  âš ï¸  é†«ç™‚å­æŒ‡æ¨™ä¸è¶³ï¼Œè·³éé†«ç™‚æŒ‡æ¨™ä¿ç•™")
    
    # è™•ç†åæ…‹åˆ†å¸ƒ
    print("\nğŸ“Š è™•ç†åæ…‹åˆ†å¸ƒ...")
    
    numeric_cols_for_skew = df.select_dtypes(include=[np.number]).columns.tolist()
    predefined_skewed = [
        GEO_AREA, COM_TOTAL_CAP, COM_TOTAL_CNT, 
        HEALTH_FACILITIES, HEALTH_BEDS, HEALTH_PERSON, 
        FACTORY_COUNT, COM_TERTIARY, COM_HHI, INCOME_HOUSEHOLDS, POP_TOTAL
    ]
    
    existing_skewed = [col for col in predefined_skewed if col in df.columns]
    
    for feature in existing_skewed:
        if feature in df.columns:
            df[feature] = np.log1p(df[feature])
    
    print(f"  âœ… è™•ç†äº† {len(existing_skewed)} å€‹åæ…‹ç‰¹å¾µ")
    
    # å‰µå»ºæ–°çš„è¡ç”Ÿç‰¹å¾µ
    if COM_TOTAL_CAP in df.columns and FACTORY_COUNT in df.columns:
        df[DERIVED_AVG_FACTORY_CAP] = np.where(
            df[FACTORY_COUNT] == 0,
            np.nan,
            df[COM_TOTAL_CAP] / df[FACTORY_COUNT]
        )
        print("  âœ… å¹³å‡å·¥å» è³‡æœ¬é¡")
    
    # åˆªé™¤ä¸å¿…è¦çš„ç‰¹å¾µ
    print("\nğŸ—‘ï¸ åˆªé™¤ä¸å¿…è¦çš„ç‰¹å¾µ...")
    
    features_to_drop = [
        COM_TOTAL_CNT, COM_TOTAL_CAP, COM_TERTIARY, INCOME_HOUSEHOLDS, 
        GEO_AREA, POP_TOTAL, HEALTH_PERSON, HEALTH_FACILITIES, HEALTH_BEDS, 
        DERIVED_ECON_INDEX, DERIVED_CAP_PER_HOUSEHOLD, DERIVED_BEDS_PER_1K, 
        DERIVED_STAFF_PER_1K, DERIVED_MED_DENSITY
    ]
    # ğŸ”„ æ–¹æ¡ˆA: ä¿ç•™é†«ç™‚å­æŒ‡æ¨™ï¼Œä¸åˆªé™¤
    # medical_beds_per_1k, medical_staff_per_1k, medical_facility_density å°‡ä¿ç•™
    
    existing_drop_features = [col for col in features_to_drop if col in df.columns]
    df = df.drop(columns=existing_drop_features)
    print(f"  âœ… åˆªé™¤äº† {len(existing_drop_features)} å€‹ç‰¹å¾µ")
    
    # æ•¸æ“šæª¢æŸ¥
    print("\nğŸ“ æ•¸æ“šæª¢æŸ¥...")
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    print(f"  ç¸½ç‰¹å¾µæ•¸: {len(numeric_cols)}")
    print(f"  ç¼ºå¤±å€¼: {df.isnull().sum().sum()}")
    
    # ä¿å­˜çµæœ
    df.to_csv('output/taoyuan_features_enhanced.csv', index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ ä¿å­˜å¢å¼·ç‰ˆç‰¹å¾µæ•¸æ“š: output/taoyuan_features_enhanced.csv")
    
    # ç”Ÿæˆå…ƒæ•¸æ“š
    metadata = {
        'total_features': len(numeric_cols),
        'total_samples': df.shape[0],
        'missing_values': int(df.isnull().sum().sum()),
        'kept_features': [col for col in df.columns if col != 'å€åŸŸåˆ¥']
    }
    
    import json
    with open('output/taoyuan_enhanced_meta.json', 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… å¢å¼·ç‰ˆç‰¹å¾µå·¥ç¨‹å®Œæˆï¼")
    print(f"ğŸ“Š æœ€çµ‚ç‰¹å¾µæ•¸é‡: {len(numeric_cols)}")
    print("="*80)
    
    return df

# ä¿®æ”¹ä¸»ç¨‹åºï¼Œè®“å¢å¼·ç‰ˆç‰¹å¾µå·¥ç¨‹æˆç‚ºé è¨­è¡Œç‚º
def main():
    """ä¸»ç¨‹åº - é è¨­åŸ·è¡Œå¢å¼·ç‰ˆç‰¹å¾µå·¥ç¨‹"""
    import sys
    
    # å…ˆåŸ·è¡ŒåŸºç¤ç‰¹å¾µå·¥ç¨‹ï¼ˆå¦‚æœé‚„æ²’æœ‰ï¼‰
    if not os.path.exists('output/taoyuan_features_numeric.csv'):
        print("ğŸ“Œ é¦–æ¬¡åŸ·è¡Œï¼Œå…ˆé€²è¡ŒåŸºç¤ç‰¹å¾µå·¥ç¨‹...")
    create_all_features() 
    
    # åŸ·è¡Œå¢å¼·ç‰ˆç‰¹å¾µå·¥ç¨‹
    enhanced_feature_engineering()

if __name__ == "__main__":
    main() 