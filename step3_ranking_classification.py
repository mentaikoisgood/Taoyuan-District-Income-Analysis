"""
æ¡ƒåœ’å¸‚è¡Œæ”¿å€3ç´šJenksåˆ†ç´šåˆ†æ
ä½¿ç”¨3ç´šJenksè‡ªç„¶æ–·é»é€²è¡Œåˆ†ç´š

å°ˆæ³¨æ–¼æ ¸å¿ƒåˆ†ç´šä»»å‹™ï¼š
1. å°5å€‹æŒ‡æ¨™é€²è¡Œz-scoreæ¨™æº–åŒ–
2. è¨­ç½®æ¬Šé‡è¨ˆç®—ç¶œåˆåˆ†æ•¸
3. ä½¿ç”¨3ç´šJenksè‡ªç„¶æ–·é»åˆ†ç´š
4. ä¿å­˜åˆ†ç´šçµæœ

è©³ç´°é©—è­‰å’Œè¦–è¦ºåŒ–è«‹åƒè€ƒ step4_validation.py
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# å˜—è©¦å°å…¥Jenksè‡ªç„¶æ–·é»
try:
    import jenkspy
    JENKS_AVAILABLE = True
    print("âœ… Jenksè‡ªç„¶æ–·é»å¯ç”¨")
except ImportError:
    JENKS_AVAILABLE = False
    print("âŒ Jenksæœªå®‰è£ï¼Œç„¡æ³•åŸ·è¡Œ3ç´šåˆ†æ")
    exit(1)

def load_data():
    """è¼‰å…¥ç‰¹å¾µæ•¸æ“š"""
    print("ğŸ“‚ è¼‰å…¥æ¡ƒåœ’å¸‚è¡Œæ”¿å€ç‰¹å¾µæ•¸æ“š...")
    
    df = pd.read_csv('output/taoyuan_features_enhanced.csv')
    districts = df['å€åŸŸåˆ¥'].tolist()
    feature_names = df.columns[1:].tolist()
    X = df[feature_names].values
    
    print(f"âœ… æ•¸æ“šè¼‰å…¥æˆåŠŸ: {len(districts)} å€‹è¡Œæ”¿å€, {len(feature_names)} å€‹ç‰¹å¾µ")
    print(f"ç‰¹å¾µåˆ—è¡¨: {feature_names}")
    
    return df, districts, feature_names, X

def get_feature_properties():
    """è·å–ç‰¹å¾µå±æ€§å’Œæ¬Šé‡ - æ–¹æ¡ˆA: çµ±ä¸€Z-scoreç­–ç•¥"""
    # ğŸ†• æ–¹æ¡ˆA: é†«ç™‚æ¬Šé‡30%åˆ†é…çµ¦3å€‹å­æŒ‡æ¨™
    feature_properties = {
        'äººå£_working_age_ratio': {'direction': 'positive', 'weight': 0.15, 'description': 'å·¥ä½œå¹´é½¡äººå£æ¯”ä¾‹'},
        'å•†æ¥­_hhi_index': {'direction': 'negative', 'weight': 0.10, 'description': 'å•†æ¥­é›†ä¸­åº¦ (è½‰åˆ†æ•£åº¦)'},
        'æ‰€å¾—_median_household_income': {'direction': 'positive', 'weight': 0.40, 'description': 'å®¶æˆ¶ä¸­ä½æ•¸æ‰€å¾—'},
        'tertiary_industry_ratio': {'direction': 'positive', 'weight': 0.05, 'description': 'æœå‹™æ¥­æ¯”ä¾‹'},
        # ğŸ¥ é†«ç™‚30%æ¬Šé‡åˆ†é…çµ¦3å€‹å­æŒ‡æ¨™
        'medical_beds_per_1k': {'direction': 'positive', 'weight': 0.10, 'description': 'æ¯åƒäººç—…åºŠæ•¸'},
        'medical_staff_per_1k': {'direction': 'positive', 'weight': 0.10, 'description': 'æ¯åƒäººé†«ç™‚äººå“¡'},
        'medical_facility_density': {'direction': 'positive', 'weight': 0.10, 'description': 'é†«ç™‚è¨­æ–½å¯†åº¦'}
    }
    
    # éªŒè¯æƒé‡æ€»å’Œ
    total_weight = sum(props['weight'] for props in feature_properties.values())
    print(f"\nğŸ” æ¬Šé‡é…ç½®é©—è­‰:")
    print(f"  æ¬Šé‡ç¸½å’Œ: {total_weight:.3f} (ç›®æ¨™: 1.000)")
    print(f"  é…ç½®èªªæ˜: æ–¹æ¡ˆAçµ±ä¸€Z-scoreç­–ç•¥ - é†«ç™‚30%æ¬Šé‡åˆ†è§£ç‚º3å€‹å­æŒ‡æ¨™")
    
    if abs(total_weight - 1.0) > 0.001:
        print(f"  âš ï¸ æ¬Šé‡ç¸½å’Œä¸ç­‰æ–¼1ï¼Œé€²è¡Œæ¨™æº–åŒ–...")
        for feature in feature_properties:
            feature_properties[feature]['weight'] /= total_weight
        
        print(f"  âœ… æ¬Šé‡å·²æ¨™æº–åŒ–")
    
    print(f"  è©³ç´°æ¬Šé‡è¨­å®š:")
    medical_total = 0
    for feature, props in feature_properties.items():
        direction_symbol = "+" if props['direction'] == 'positive' else "-"
        weight_pct = f"{props['weight']:.1%}"
        if feature.startswith('medical_'):
            weight_pct += " ğŸ¥"
            medical_total += props['weight']
        elif props['weight'] >= 0.3:
            weight_pct += " ğŸ¯é«˜æ¬Šé‡"
        elif props['weight'] <= 0.1:
            weight_pct += " ğŸ”½ä½æ¬Šé‡"
        print(f"    {feature}: {weight_pct} ({direction_symbol}) - {props['description']}")
    
    print(f"  ğŸ“Š é†«ç™‚ç¸½æ¬Šé‡: {medical_total:.1%} (3å€‹å­æŒ‡æ¨™)")
    
    return feature_properties

def calculate_composite_scores(df, feature_names, feature_properties):
    """è¨ˆç®—ç¶œåˆåˆ†æ•¸"""
    print("\nğŸ§® è¨ˆç®—ç¶œåˆåˆ†æ•¸...")
    
    # Z-scoreæ¨™æº–åŒ–
    scaler = StandardScaler()
    X_standardized = scaler.fit_transform(df[feature_names])
    
    # è¨ˆç®—åŠ æ¬Šç¶œåˆåˆ†æ•¸
    composite_scores = np.zeros(len(df))
    
    for i, feature in enumerate(feature_names):
        weight = feature_properties[feature]['weight']
        direction = feature_properties[feature]['direction']
        
        if direction == 'positive':
            feature_score = X_standardized[:, i] * weight
        else:
            feature_score = -X_standardized[:, i] * weight
        
        composite_scores += feature_score
    
    # æ­£è¦åŒ–åˆ°0-10åˆ†
    min_score = np.min(composite_scores)
    max_score = np.max(composite_scores)
    normalized_scores = ((composite_scores - min_score) / (max_score - min_score)) * 10
    
    print(f"åˆ†æ•¸çµ±è¨ˆ: ç¯„åœ[{np.min(normalized_scores):.1f}, {np.max(normalized_scores):.1f}], å¹³å‡{np.mean(normalized_scores):.1f} (0-10åˆ†åˆ¶)")
    
    return normalized_scores

def jenks_3_level_classification(scores, districts):
    """ä½¿ç”¨3ç´šJenksè‡ªç„¶æ–·é»åˆ†ç´š"""
    print(f"\nğŸ“Š åŸ·è¡Œ3ç´šJenksè‡ªç„¶æ–·é»åˆ†ç´š...")
    
    # 3ç´šæ¨™ç±¤
    labels_names = ['ä½æ½›åŠ›', 'ä¸­æ½›åŠ›', 'é«˜æ½›åŠ›']
    
    try:
        # ä½¿ç”¨Jenksè‡ªç„¶æ–·é»
        breaks = jenkspy.jenks_breaks(scores, n_classes=3)
        labels = []
        
        for score in scores:
            if score <= breaks[1]:
                labels.append('ä½æ½›åŠ›')
            elif score <= breaks[2]:
                labels.append('ä¸­æ½›åŠ›')
            else:
                labels.append('é«˜æ½›åŠ›')
        
        labels = pd.Categorical(labels, categories=labels_names)
        
        print(f"åˆ†å‰²é»: {[f'{cut:.2f}' for cut in breaks]}")
        
        # çµ±è¨ˆå„ç´šåˆ¥
        level_counts = pd.Series(labels).value_counts()
        print(f"åˆ†ç´šçµæœ:")
        for level in labels_names:
            if level in level_counts:
                districts_in_level = [districts[i] for i, label in enumerate(labels) if label == level]
                print(f"  {level}: {level_counts[level]} å€‹å€åŸŸ - {', '.join(districts_in_level)}")
        
        return labels, breaks
                
    except Exception as e:
        print(f"âŒ 3ç´šJenksåˆ†ç´šå¤±æ•—: {e}")
        return None, None

def save_results(df, districts, normalized_scores, labels, breaks, feature_names, feature_properties):
    """ä¿å­˜åˆ†ç´šçµæœ"""
    print("\nğŸ’¾ ä¿å­˜åˆ†ç´šçµæœ...")
    
    # å‰µå»ºçµæœDataFrame
    results_df = pd.DataFrame({
        'å€åŸŸåˆ¥': districts,
        'ç¶œåˆåˆ†æ•¸': normalized_scores,
        '3ç´šJenksåˆ†ç´š': labels,
    })
    
    # æ·»åŠ åŸå§‹ç‰¹å¾µ
    for feature in feature_names:
        results_df[feature] = df[feature].values
    
    # æŒ‰åˆ†æ•¸æ’åº
    results_df = results_df.sort_values('ç¶œåˆåˆ†æ•¸', ascending=False).reset_index(drop=True)
    results_df['æ’å'] = range(1, len(results_df) + 1)
    
    # é‡æ–°æ’åˆ—åˆ—é †åº
    cols = ['æ’å', 'å€åŸŸåˆ¥', 'ç¶œåˆåˆ†æ•¸', '3ç´šJenksåˆ†ç´š']
    cols.extend(feature_names)
    results_df = results_df[cols]
    
    # ä¿å­˜CSV
    csv_path = 'output/3_level_jenks_results.csv'
    results_df.to_csv(csv_path, index=False, encoding='utf-8')
    
    # ä¿å­˜é…ç½®ä¿¡æ¯
    config = {
        'method': '3ç´šJenksè‡ªç„¶æ–·é»',
        'breaks': breaks if breaks is not None else None,
        'feature_properties': feature_properties,
        'n_districts': len(districts),
        'score_range': [float(np.min(normalized_scores)), float(np.max(normalized_scores))]
    }
    
    import json
    config_path = 'output/3_level_jenks_config.json'
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… çµæœå·²ä¿å­˜: {csv_path}")
    print(f"âœ… é…ç½®å·²ä¿å­˜: {config_path}")
    
    return csv_path, config_path

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¯ STEP 3 - æ¡ƒåœ’å¸‚è¡Œæ”¿å€3ç´šJenksåˆ†ç´šåˆ†æ")
    print("="*60)
    
    # è¼‰å…¥æ•¸æ“š
    df, districts, feature_names, X = load_data()
    
    # ç²å–ç‰¹å¾µå±¬æ€§
    feature_properties = get_feature_properties()
    
    # è¨ˆç®—ç¶œåˆåˆ†æ•¸
    normalized_scores = calculate_composite_scores(df, feature_names, feature_properties)
    
    # 3ç´šJenksåˆ†ç´š
    labels, breaks = jenks_3_level_classification(normalized_scores, districts)
    
    if labels is None:
        print("âŒ åˆ†ç´šå¤±æ•—")
        return
    
    # ä¿å­˜çµæœ
    csv_path, config_path = save_results(df, districts, normalized_scores, labels, breaks, 
                                       feature_names, feature_properties)
    
    # é¡¯ç¤ºæœ€çµ‚æ’å
    sorted_indices = np.argsort(normalized_scores)[::-1]
    print(f"\nğŸ† æœ€çµ‚æ’å (0-10åˆ†åˆ¶):")
    for i in range(len(districts)):
        idx = sorted_indices[i]
        print(f"  {i+1:2d}. {districts[idx]:4s}: {normalized_scores[idx]:4.1f}åˆ† ({labels[idx]})")
    
    print(f"\nâœ… STEP 3 å®Œæˆ! è«‹åŸ·è¡Œ step4_validation.py é€²è¡Œè©³ç´°é©—è­‰åˆ†æ")

if __name__ == "__main__":
    main() 