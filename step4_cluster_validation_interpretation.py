"""
STEP 4 - ç¾¤é›†é©—è­‰èˆ‡è§£è®€ (ç¶œåˆè©•ä¼°ç‰ˆ)

åŒ…å«ï¼š
1. ç¾¤å…§/ç¾¤é–“è·é›¢åˆ†æ
2. Silhouetteåˆ†æ•¸è¨ˆç®— (å¹¾ä½•è³ªé‡)
3. æ½›åŠ›åˆ†æ•¸ä¸€è‡´æ€§è©•ä¼° (èªç¾©è³ªé‡)
4. ç®±å‹åœ–å’Œé›·é”åœ–è¦–è¦ºåŒ–
5. ç¶œåˆè©•ä¼°å ±å‘Š
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics import silhouette_score, silhouette_samples
from sklearn.metrics import pairwise_distances
from scipy import stats
import warnings
import os
import matplotlib

warnings.filterwarnings('ignore')

# è¨­å®šä¸­æ–‡å­—é«”
matplotlib.rcParams['font.family'] = ['sans-serif']
matplotlib.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False

OUTPUT_DIR = 'output'
RANDOM_STATE = 42

def load_data_and_cluster():
    """è¼‰å…¥æ•¸æ“šä¸¦åŸ·è¡Œèšé¡"""
    print("ğŸ“‚ è¼‰å…¥æ•¸æ“šä¸¦åŸ·è¡Œèšé¡...")
    
    # è¼‰å…¥ç‰¹å¾µæ•¸æ“š
    df = pd.read_csv('output/taoyuan_features_enhanced.csv')
    districts = df['å€åŸŸåˆ¥'].tolist()
    
    # ğŸ”§ ä½¿ç”¨èˆ‡STEP3ç›¸åŒçš„æœ€ä½³ç‰¹å¾çµ„åˆ
    optimal_features = [
        'æ‰€å¾—_median_household_income',  # ç¶“æ¿Ÿæ°´å¹³æŒ‡æ¨™
        'medical_index',                # é†«ç™‚æœå‹™æŒ‡æ¨™
        'tertiary_industry_ratio'       # ç”¢æ¥­çµæ§‹æŒ‡æ¨™
    ]
    
    X = df[optimal_features].values
    feature_names = optimal_features
    
    print(f"âœ… ä½¿ç”¨æœ€ä½³ç‰¹å¾çµ„åˆ: {len(districts)} å€‹è¡Œæ”¿å€, {X.shape[1]} å€‹ç‰¹å¾")
    print(f"  ç‰¹å¾åˆ—è¡¨: {', '.join(optimal_features)}")
    
    # t-SNEé™ç¶­
    tsne = TSNE(n_components=2, random_state=RANDOM_STATE, perplexity=3, max_iter=1000)
    X_tsne = tsne.fit_transform(X)
    
    # Wardå±¤æ¬¡èšé¡
    ward = AgglomerativeClustering(n_clusters=3, linkage='ward')
    cluster_labels = ward.fit_predict(X_tsne)
    
    # è¼‰å…¥èšé¡çµæœï¼ˆåŒ…å«æ½›åŠ›ç­‰ç´šï¼‰
    cluster_results = pd.read_csv('output/clustering_results.csv')
    potential_labels = []
    for district in districts:
        row = cluster_results[cluster_results['è¡Œæ”¿å€'] == district]
        potential_labels.append(row['æ½›åŠ›ç­‰ç´š'].iloc[0])
    
    return X, X_tsne, cluster_labels, districts, feature_names, df, potential_labels, cluster_results

def analyze_cluster_distances(X_tsne, cluster_labels, districts):
    """åˆ†æç¾¤å…§/ç¾¤é–“è·é›¢"""
    print("\nğŸ“ ç¾¤å…§/ç¾¤é–“è·é›¢åˆ†æ (å¹¾ä½•è³ªé‡)")
    print("="*40)
    
    # è¨ˆç®—ç¾¤å…§è·é›¢ï¼ˆWithin-cluster distanceï¼‰
    within_cluster_distances = []
    for cluster_id in range(3):
        cluster_mask = cluster_labels == cluster_id
        cluster_points = X_tsne[cluster_mask]
        
        if len(cluster_points) > 1:
            # è¨ˆç®—ç¾¤å…§é»å°è·é›¢çš„å¹³å‡å€¼
            intra_distances = pairwise_distances(cluster_points)
            # å–ä¸Šä¸‰è§’çŸ©é™£ï¼ˆé¿å…é‡è¤‡è¨ˆç®—å’Œå°è§’ç·šï¼‰
            upper_triangle = np.triu(intra_distances, k=1)
            within_dist = upper_triangle[upper_triangle > 0].mean()
        else:
            within_dist = 0
        
        within_cluster_distances.append(within_dist)
        cluster_districts = [districts[i] for i in range(len(districts)) if cluster_labels[i] == cluster_id]
        print(f"  é›†ç¾¤ {cluster_id}: ç¾¤å…§å¹³å‡è·é›¢ = {within_dist:.2f}")
        print(f"    åŒ…å«è¡Œæ”¿å€: {', '.join(cluster_districts)}")
    
    # è¨ˆç®—ç¾¤é–“è·é›¢ï¼ˆBetween-cluster distanceï¼‰
    print(f"\nç¾¤é–“è·é›¢:")
    cluster_centers = []
    for cluster_id in range(3):
        cluster_mask = cluster_labels == cluster_id
        center = X_tsne[cluster_mask].mean(axis=0)
        cluster_centers.append(center)
    
    between_distances = pairwise_distances(cluster_centers)
    for i in range(3):
        for j in range(i+1, 3):
            dist = between_distances[i, j]
            print(f"  é›†ç¾¤ {i} â†” é›†ç¾¤ {j}: {dist:.2f}")
    
    # è¨ˆç®— Davies-Bouldin æŒ‡æ•¸
    db_scores = []
    for i in range(3):
        max_ratio = 0
        for j in range(3):
            if i != j:
                ratio = (within_cluster_distances[i] + within_cluster_distances[j]) / between_distances[i, j]
                max_ratio = max(max_ratio, ratio)
        db_scores.append(max_ratio)
    
    db_index = np.mean(db_scores)
    print(f"\nğŸ“Š Davies-Bouldin æŒ‡æ•¸: {db_index:.3f} (è¶Šå°è¶Šå¥½ï¼Œ<1.5ç‚ºè‰¯å¥½)")
    
    return within_cluster_distances, between_distances

def analyze_silhouette_scores(X_tsne, cluster_labels, districts):
    """è©³ç´°çš„Silhouetteåˆ†æ"""
    print("\nğŸ¯ Silhouette åˆ†æ•¸åˆ†æ (å¹¾ä½•è³ªé‡)")
    print("="*40)
    
    # æ•´é«”Silhouetteåˆ†æ•¸
    overall_silhouette = silhouette_score(X_tsne, cluster_labels)
    print(f"æ•´é«” Silhouette åˆ†æ•¸: {overall_silhouette:.3f}")
    
    # è§£é‡‹åˆ†æ•¸
    if overall_silhouette > 0.7:
        quality = "å„ªç§€"
    elif overall_silhouette > 0.4:
        quality = "è‰¯å¥½"  
    elif overall_silhouette > 0.2:
        quality = "ä¸€èˆ¬"
    else:
        quality = "è¼ƒå·®"
    print(f"å¹¾ä½•èšé¡è³ªé‡: {quality}")
    
    # å„é»çš„Silhouetteåˆ†æ•¸
    sample_silhouettes = silhouette_samples(X_tsne, cluster_labels)
    
    print(f"\nå„è¡Œæ”¿å€ Silhouette åˆ†æ•¸:")
    for i, (district, score) in enumerate(zip(districts, sample_silhouettes)):
        cluster = cluster_labels[i]
        print(f"  {district} (é›†ç¾¤{cluster}): {score:.3f}")
    
    # å„é›†ç¾¤å¹³å‡Silhouetteåˆ†æ•¸
    print(f"\nå„é›†ç¾¤å¹³å‡ Silhouette åˆ†æ•¸:")
    for cluster_id in range(3):
        cluster_mask = cluster_labels == cluster_id
        cluster_silhouettes = sample_silhouettes[cluster_mask]
        avg_silhouette = cluster_silhouettes.mean()
        print(f"  é›†ç¾¤ {cluster_id}: {avg_silhouette:.3f}")
    
    return sample_silhouettes

def evaluate_potential_consistency(cluster_results):
    """è©•ä¼°æ½›åŠ›åˆ†æ•¸èˆ‡èšé¡çµæœçš„ä¸€è‡´æ€§"""
    print("\nğŸ§® æ½›åŠ›åˆ†æ•¸ä¸€è‡´æ€§è©•ä¼° (èªç¾©è³ªé‡)")
    print("="*40)
    
    # è¨ˆç®—å„é›†ç¾¤çš„æ½›åŠ›åˆ†æ•¸çµ±è¨ˆ
    cluster_stats = {}
    for cluster_id in range(3):
        cluster_data = cluster_results[cluster_results['é›†ç¾¤ç·¨è™Ÿ'] == cluster_id]
        potential_scores = cluster_data['æ½›åŠ›åˆ†æ•¸'].values
        
        cluster_stats[cluster_id] = {
            'count': len(cluster_data),
            'districts': cluster_data['è¡Œæ”¿å€'].tolist(),
            'potential_level': cluster_data['æ½›åŠ›ç­‰ç´š'].iloc[0],
            'mean_score': potential_scores.mean(),
            'std_score': potential_scores.std(),
            'min_score': potential_scores.min(),
            'max_score': potential_scores.max()
        }
        
        print(f"é›†ç¾¤ {cluster_id} ({cluster_stats[cluster_id]['potential_level']}):")
        print(f"  è¡Œæ”¿å€: {', '.join(cluster_stats[cluster_id]['districts'])}")
        print(f"  æ½›åŠ›åˆ†æ•¸: {cluster_stats[cluster_id]['mean_score']:.3f} Â± {cluster_stats[cluster_id]['std_score']:.3f}")
        print(f"  åˆ†æ•¸ç¯„åœ: [{cluster_stats[cluster_id]['min_score']:.3f}, {cluster_stats[cluster_id]['max_score']:.3f}]")
    
    # è¨ˆç®—é›†ç¾¤é–“åˆ†é›¢åº¦ (æ½›åŠ›åˆ†æ•¸)
    print(f"\né›†ç¾¤é–“æ½›åŠ›åˆ†æ•¸åˆ†é›¢åº¦:")
    cluster_means = [cluster_stats[i]['mean_score'] for i in range(3)]
    separation_score = max(cluster_means) - min(cluster_means)
    print(f"  åˆ†æ•¸ç¯„åœè·¨åº¦: {separation_score:.3f}")
    
    # æª¢æŸ¥é›†ç¾¤å…§ä¸€è‡´æ€§
    print(f"\né›†ç¾¤å…§ä¸€è‡´æ€§æª¢æŸ¥:")
    consistency_scores = []
    for cluster_id in range(3):
        std = cluster_stats[cluster_id]['std_score']
        consistency = 1 / (1 + std)  # æ¨™æº–å·®è¶Šå°ï¼Œä¸€è‡´æ€§è¶Šé«˜
        consistency_scores.append(consistency)
        print(f"  é›†ç¾¤ {cluster_id}: ä¸€è‡´æ€§åˆ†æ•¸ = {consistency:.3f} (è¶Šæ¥è¿‘1è¶Šå¥½)")
    
    overall_consistency = np.mean(consistency_scores)
    print(f"\nğŸ¯ ç¸½é«”èªç¾©ä¸€è‡´æ€§: {overall_consistency:.3f}")
    
    return cluster_stats, overall_consistency

def calculate_comprehensive_score(silhouette_score, consistency_score, db_index):
    """è¨ˆç®—ç¶œåˆè©•ä¼°åˆ†æ•¸"""
    print("\nğŸ† ç¶œåˆè©•ä¼°åˆ†æ•¸")
    print("="*40)
    
    # æ­£è¦åŒ–å„æŒ‡æ¨™ (0-1ç¯„åœ)
    # Silhouette: 0.463 -> ç´„ 0.6 (åœ¨ 0-1 ç¯„åœå…§)
    norm_silhouette = max(0, min(1, (silhouette_score + 1) / 2))  # å¾ [-1,1] è½‰æ›åˆ° [0,1]
    
    # ä¸€è‡´æ€§: å·²ç¶“åœ¨ 0-1 ç¯„åœ
    norm_consistency = consistency_score
    
    # Davies-Bouldin: è¶Šå°è¶Šå¥½ï¼Œ1.112 -> ç´„ 0.47 (1/(1+DB))
    norm_db = 1 / (1 + db_index)
    
    print(f"æ¨™æº–åŒ–æŒ‡æ¨™:")
    print(f"  å¹¾ä½•è³ªé‡ (Silhouette): {norm_silhouette:.3f}")
    print(f"  èªç¾©ä¸€è‡´æ€§: {norm_consistency:.3f}")
    print(f"  åˆ†é›¢åº¦ (Davies-Bouldin): {norm_db:.3f}")
    
    # è¨ˆç®—åŠ æ¬Šç¶œåˆåˆ†æ•¸
    weights = [0.3, 0.5, 0.2]  # æ›´é‡è¦–èªç¾©ä¸€è‡´æ€§
    comprehensive_score = (
        weights[0] * norm_silhouette + 
        weights[1] * norm_consistency + 
        weights[2] * norm_db
    )
    
    print(f"\nğŸ¯ ç¶œåˆè©•ä¼°åˆ†æ•¸: {comprehensive_score:.3f}")
    
    if comprehensive_score > 0.8:
        grade = "å„ªç§€"
    elif comprehensive_score > 0.6:
        grade = "è‰¯å¥½"
    elif comprehensive_score > 0.4:
        grade = "ä¸€èˆ¬"
    else:
        grade = "éœ€æ”¹é€²"
    
    print(f"ç¶œåˆè©•ç´š: {grade}")
    
    return comprehensive_score

def create_boxplots(df, cluster_labels, feature_names):
    """å‰µå»ºç®±å‹åœ–æ¯”è¼ƒå„ç¾¤ç‰¹å¾µåˆ†å¸ƒ"""
    print("\nğŸ“Š å‰µå»ºç®±å‹åœ–...")
    
    # æº–å‚™æ•¸æ“š
    plot_data = df.copy()
    plot_data['é›†ç¾¤'] = cluster_labels
    
    # å‰µå»ºå­åœ–
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    axes = axes.flatten()
    
    for i, feature in enumerate(feature_names):
        sns.boxplot(data=plot_data, x='é›†ç¾¤', y=feature, ax=axes[i])
        axes[i].set_title(f'{feature}', fontsize=10)
        axes[i].tick_params(axis='both', labelsize=8)
    
    # éš±è—å¤šé¤˜çš„å­åœ–
    if len(feature_names) < len(axes):
        axes[-1].set_visible(False)
    
    plt.tight_layout()
    plt.suptitle('å„é›†ç¾¤ç‰¹å¾µåˆ†å¸ƒç®±å‹åœ–', fontsize=14, y=1.02)
    
    # ä¿å­˜åœ–ç‰‡
    boxplot_path = os.path.join(OUTPUT_DIR, 'cluster_boxplots.png')
    plt.savefig(boxplot_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… ç®±å‹åœ–å·²ä¿å­˜: {boxplot_path}")
    
    return boxplot_path

def create_radar_chart(X, cluster_labels, feature_names, districts, potential_labels):
    """å‰µå»ºé›·é”åœ–å±•ç¤ºå„ç¾¤ç‰¹å¾µå¹³å‡å€¼"""
    print("\nğŸ•¸ï¸ å‰µå»ºé›·é”åœ–...")
    
    # æ¨™æº–åŒ–ç‰¹å¾µå€¼åˆ°0-1ç¯„åœ
    from sklearn.preprocessing import MinMaxScaler
    scaler = MinMaxScaler()
    X_scaled = scaler.fit_transform(X)
    
    # è¨ˆç®—å„ç¾¤ç‰¹å¾µå¹³å‡å€¼
    cluster_means = []
    cluster_labels_unique = []
    for cluster_id in range(3):
        cluster_mask = cluster_labels == cluster_id
        means = X_scaled[cluster_mask].mean(axis=0)
        cluster_means.append(means)
        
        # ç²å–è©²é›†ç¾¤çš„æ½›åŠ›ç­‰ç´š
        cluster_districts = [districts[i] for i in range(len(districts)) if cluster_labels[i] == cluster_id]
        cluster_potential = potential_labels[cluster_labels.tolist().index(cluster_id)]
        cluster_labels_unique.append(f'é›†ç¾¤{cluster_id} ({cluster_potential})')
    
    # è¨­å®šé›·é”åœ–
    angles = np.linspace(0, 2 * np.pi, len(feature_names), endpoint=False).tolist()
    angles += angles[:1]  # é–‰åˆåœ–å½¢
    
    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))
    
    colors = ['#e74c3c', '#3498db', '#f39c12']  # ç´…ã€è—ã€æ©™
    
    for cluster_id, (means, color, label) in enumerate(zip(cluster_means, colors, cluster_labels_unique)):
        values = means.tolist()
        values += values[:1]  # é–‰åˆåœ–å½¢
        
        ax.plot(angles, values, 'o-', linewidth=2, label=label, color=color)
        ax.fill(angles, values, alpha=0.25, color=color)
    
    # è¨­å®šæ¨™ç±¤
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(feature_names, fontsize=10)
    ax.set_ylim(0, 1)
    ax.set_title('å„é›†ç¾¤ç‰¹å¾µé›·é”åœ– (åŸºæ–¼æ½›åŠ›ç¶œåˆåˆ†æ•¸)', fontsize=14, pad=20)
    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
    ax.grid(True)
    
    # ä¿å­˜åœ–ç‰‡
    radar_path = os.path.join(OUTPUT_DIR, 'cluster_radar_chart.png')
    plt.savefig(radar_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… é›·é”åœ–å·²ä¿å­˜: {radar_path}")
    
    return radar_path

def main():
    """ä¸»å‡½æ•¸"""
    print("="*60)
    print("ğŸš€ STEP 4 - ç¾¤é›†é©—è­‰èˆ‡è§£è®€ (ç¶œåˆè©•ä¼°ç‰ˆ)")
    print("="*60)
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # 1. è¼‰å…¥æ•¸æ“šä¸¦åŸ·è¡Œèšé¡
    X, X_tsne, cluster_labels, districts, feature_names, df, potential_labels, cluster_results = load_data_and_cluster()
    
    # 2. å¹¾ä½•è³ªé‡åˆ†æ
    within_distances, between_distances = analyze_cluster_distances(X_tsne, cluster_labels, districts)
    silhouette_scores = analyze_silhouette_scores(X_tsne, cluster_labels, districts)
    overall_silhouette = silhouette_score(X_tsne, cluster_labels)
    
    # è¨ˆç®—Davies-BouldinæŒ‡æ•¸
    db_scores = []
    for i in range(3):
        max_ratio = 0
        for j in range(3):
            if i != j:
                ratio = (within_distances[i] + within_distances[j]) / between_distances[i, j]
                max_ratio = max(max_ratio, ratio)
        db_scores.append(max_ratio)
    db_index = np.mean(db_scores)
    
    # 3. èªç¾©è³ªé‡åˆ†æ
    cluster_stats, consistency_score = evaluate_potential_consistency(cluster_results)
    
    # 4. ç¶œåˆè©•ä¼°
    comprehensive_score = calculate_comprehensive_score(overall_silhouette, consistency_score, db_index)
    
    # 5. è¦–è¦ºåŒ–åˆ†æ
    boxplot_path = create_boxplots(df, cluster_labels, feature_names)
    radar_path = create_radar_chart(X, cluster_labels, feature_names, districts, potential_labels)
    
    print(f"\nâœ… ç¾¤é›†é©—è­‰èˆ‡è§£è®€å®Œæˆ!")
    print(f"  - ç®±å‹åœ–: {boxplot_path}")
    print(f"  - é›·é”åœ–: {radar_path}")
    print(f"\nğŸ“Š é—œéµæŒ‡æ¨™ç¸½çµ:")
    print(f"  - å¹¾ä½• Silhouette åˆ†æ•¸: {overall_silhouette:.3f} (è‰¯å¥½)")
    print(f"  - èªç¾©ä¸€è‡´æ€§åˆ†æ•¸: {consistency_score:.3f}")
    print(f"  - Davies-Bouldin æŒ‡æ•¸: {db_index:.3f}")
    print(f"  - ç¶œåˆè©•ä¼°åˆ†æ•¸: {comprehensive_score:.3f}")

if __name__ == "__main__":
    main() 